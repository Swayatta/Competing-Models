{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Graph+Sequence Labeller.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "50b5a9f8e44e4884b8b6089bd4724a7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_18fbe0e697a84bacbabe59f56fe08cdc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_300daeff2eae4a5294fb2029d2bb1aff",
              "IPY_MODEL_a50a4eecfc464f03b6a11d0866c53717",
              "IPY_MODEL_0a48f4747d9748858f085f2bbc15b568"
            ]
          }
        },
        "18fbe0e697a84bacbabe59f56fe08cdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "300daeff2eae4a5294fb2029d2bb1aff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_50a535fa160347c78ce551f1432680d8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_64fe645ab9e048df8a7cf804b54208ca"
          }
        },
        "a50a4eecfc464f03b6a11d0866c53717": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2aacca41c2424b829ee99a840866a891",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 385,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 385,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a994655fba9e46d099efb4dd1c555eef"
          }
        },
        "0a48f4747d9748858f085f2bbc15b568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b6af30d704554d3080711804437914f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 385/385 [00:00&lt;00:00, 8.55kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0daaaae9ee17408caae74c590a987cfe"
          }
        },
        "50a535fa160347c78ce551f1432680d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "64fe645ab9e048df8a7cf804b54208ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2aacca41c2424b829ee99a840866a891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a994655fba9e46d099efb4dd1c555eef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6af30d704554d3080711804437914f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0daaaae9ee17408caae74c590a987cfe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ecd58ea81a94c34bb0d0af03b012758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bcc5abeaf78642659ceca109bfc7451f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3ab8b0652dbb4d61b1d2756410fd8ce5",
              "IPY_MODEL_1e20e2c003444fad999c2dc2377e4455",
              "IPY_MODEL_7027ed5dc24e4e73a945c5950abdfaca"
            ]
          }
        },
        "bcc5abeaf78642659ceca109bfc7451f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ab8b0652dbb4d61b1d2756410fd8ce5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_535a7a7d16d74a75b2b0c6e86f6a0a61",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_442d333125834c53a48e894d5d6629e9"
          }
        },
        "1e20e2c003444fad999c2dc2377e4455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_33d06719a10842468ecc133481f16ad4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442221694,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442221694,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3706887119d47afa669db636ffbb890"
          }
        },
        "7027ed5dc24e4e73a945c5950abdfaca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_40435075b3c144e298118083b9258d86",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 422M/422M [00:12&lt;00:00, 36.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b70fe2842a2340b3b8272ef1d405cc82"
          }
        },
        "535a7a7d16d74a75b2b0c6e86f6a0a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "442d333125834c53a48e894d5d6629e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33d06719a10842468ecc133481f16ad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3706887119d47afa669db636ffbb890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40435075b3c144e298118083b9258d86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b70fe2842a2340b3b8272ef1d405cc82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c60e253bd85445c9938670a5ec74a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_43c43ead98244ced8f3b14025dbef6a5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e27d7ca11e9c4373b24cef159438de29",
              "IPY_MODEL_989f543e3ca64800b6c316fc3b165a96",
              "IPY_MODEL_4b916a96ceb8482eaa28855ef5ef9be0"
            ]
          }
        },
        "43c43ead98244ced8f3b14025dbef6a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e27d7ca11e9c4373b24cef159438de29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5559d9d88faf4d4980b653ba3df34e7f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e8019898d9414659a2203a8051e1469c"
          }
        },
        "989f543e3ca64800b6c316fc3b165a96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_726b86e0fc2f41138345c7ffa90b3cbb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 227845,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 227845,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43a851b294ca42e7845892a429df2957"
          }
        },
        "4b916a96ceb8482eaa28855ef5ef9be0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cd1cc10fd827416fb98613e874913808",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 223k/223k [00:00&lt;00:00, 3.31MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_48c262b5fa02432c8abbd1aec2e9a53b"
          }
        },
        "5559d9d88faf4d4980b653ba3df34e7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e8019898d9414659a2203a8051e1469c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "726b86e0fc2f41138345c7ffa90b3cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43a851b294ca42e7845892a429df2957": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cd1cc10fd827416fb98613e874913808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "48c262b5fa02432c8abbd1aec2e9a53b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsXSEH6RncDl",
        "outputId": "2b10cd80-f463-4373-e477-03f82527080e"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qy5AQmzbU0ur"
      },
      "source": [
        "# !rm -r citation_sentences\n",
        "!rm -r output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OD2GVKvZ16M"
      },
      "source": [
        "## SciBERT+CRF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IfqufvF6ZFCS",
        "outputId": "f89b01bd-29c7-42d5-e696-9c11b5b05df6"
      },
      "source": [
        "!pip install -U transformers\n",
        "!pip install pytorch-crf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: pytorch-crf in /usr/local/lib/python3.7/dist-packages (0.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wq0A3Xr8ZwcF",
        "outputId": "241da917-7d72-430c-9836-74a8db2ce437"
      },
      "source": [
        "\n",
        "#sample prediction\n",
        "from io import open\n",
        "import unicodedata\n",
        "import string\n",
        "import re\n",
        "import random\n",
        "import pickle \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils import data \n",
        "from transformers import BertTokenizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "import numpy as np\n",
        "import os\n",
        "from transformers import BertPreTrainedModel, BertModel\n",
        "from torchcrf import CRF\n",
        "import timeit\n",
        "import subprocess\n",
        "from tqdm import tqdm, trange\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "from matplotlib import pyplot as plt \n",
        "import datetime\n",
        "# from config import Config as config\n",
        "import spacy\n",
        "import torch\n",
        "tokenizer = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\", \"ner\"])\n",
        "log_soft = F.log_softmax\n",
        "import sys\n",
        "from optparse import OptionParser\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize,word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('words')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogpN1Sqs3A9y"
      },
      "source": [
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "stop = set(stopwords.words('english'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCw6PtCRZNvt"
      },
      "source": [
        "def remove_colon_and_period(sentence):\n",
        "    # punc = !.:\n",
        "    return sentence.translate(str.maketrans('', '', \".:\"))\n",
        "    \n",
        "def preprocess_corpus(sentence):\n",
        "  # text = text.lower()\n",
        "  # text = re.compile('[-]').sub('',text)\n",
        "  # regex = re.compile('[^a-zA-Z]')\n",
        "  #First parameter is the replacement, second parameter is your input string\n",
        "  # text = regex.sub(' ', text)\n",
        "  sentence = remove_colon_and_period(sentence)\n",
        "  words = []\n",
        "  for word,pos in pos_tag([w for w in word_tokenize(sentence)]):\n",
        "      if '-' in word and word.index('-')+1 < len(word) and word[word.index('-')+1].isupper():\n",
        "        word = word.replace('-','')\n",
        "      words.append(word)\n",
        "  return ' '.join(words)\n",
        "\n",
        "class Bert_CRF(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super(Bert_CRF, self).__init__(config)\n",
        "        self.num_labels = config.num_labels\n",
        "        self.bert = BertModel(config)\n",
        "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.classifier = nn.Linear(config.hidden_size, self.num_labels)\n",
        "        self.init_weights()\n",
        "        self.crf = CRF(self.num_labels, batch_first=True)    \n",
        "    \n",
        "    def forward(self, input_ids, attn_masks, labels=None):  # dont confuse this with _forward_alg above.\n",
        "        outputs = self.bert(input_ids, attn_masks)\n",
        "        sequence_output = outputs[0]\n",
        "        sequence_output = self.dropout(sequence_output)\n",
        "        emission = self.classifier(sequence_output)        \n",
        "        attn_masks = attn_masks.type(torch.uint8)\n",
        "        if labels is not None:\n",
        "            loss = -self.crf(log_soft(emission, 2), labels, mask=attn_masks, reduction='mean')\n",
        "            return loss\n",
        "        else:\n",
        "            prediction = self.crf.decode(emission, mask=attn_masks)\n",
        "            return prediction\n",
        "\n",
        "def get_algo_entities(sentence,scibertmodel):\n",
        "    spacy_tokenizer = spacy.load(\"en_core_web_sm\", disable=[\"tagger\", \"parser\", \"ner\"])\n",
        "    # sentence = word+\" \"+ \"is a very popular classifier due to its robustness against large feature vectors and sparse data.\"\n",
        "#     sentence = '''However, these word-granularity models\n",
        "# are unable to fully capture the semantic features embedded in sentences, some-\n",
        "# times even produce noise and thus hurt the performance of sentence matching.\n",
        "# Eventually, more and more researchers turn to design semantic matching strategy\n",
        "# combing word and phrase granularity, such as MultiGranCNN [24], MV-LSTM\n",
        "# [15], MPCM [22], BiMPM [21], DIIN [3].'''\n",
        "    sentence = preprocess_corpus(sentence)\n",
        "    tokens = spacy_tokenizer(sentence) \n",
        "    bert_tokens = np.array(['[CLS]'])\n",
        "    orig_to_tok_map = np.array([], dtype=\"i\")\n",
        "    begins = np.array([], dtype=\"i\")\n",
        "    ends = np.array([], dtype=\"i\")\n",
        "    original_token = np.array([])\n",
        "    bert_tokenizer = BertTokenizer.from_pretrained('allenai/scibert_scivocab_uncased')\n",
        "    offset = 0\n",
        "    for tmp_tok in tokens:\n",
        "        new_token = np.array(bert_tokenizer.tokenize(tmp_tok.text))\n",
        "        original_token = np.append(original_token, new_token)\n",
        "        orig_to_tok_map = np.append(orig_to_tok_map, bert_tokens.shape[0])\n",
        "        bert_tokens = np.append(bert_tokens, new_token)\n",
        "        offset = sentence.find(tmp_tok.text)\n",
        "        begins = np.append(begins, offset)\n",
        "        ends = np.append(ends, offset + len(tmp_tok.text))\n",
        "        offset += len(tmp_tok.text)\n",
        "    bert_tokens = np.append(bert_tokens, '[SEP]')\n",
        "    tok_ids = bert_tokenizer.convert_tokens_to_ids(bert_tokens)\n",
        "    attn_mask = [1] * len(tok_ids)   \n",
        "    tok_ids = torch.LongTensor([tok_ids])   \n",
        "    attn_mask = torch.LongTensor([attn_mask])\n",
        "    # token_ids, attn_mask, org_tok_map\n",
        "    inputs = {'input_ids': tok_ids.to(device),\n",
        "              'attn_masks' : attn_mask.to(device)\n",
        "            }  \n",
        "    with torch.torch.no_grad():\n",
        "        tag_seqs = scibertmodel(**inputs)\n",
        "    # for tok,tag in zip(bert_tokens,tag_seqs[0]):\n",
        "    #  print(tok,tag) \n",
        "    # print(bert_tokens)\n",
        "    pretok_sent = \"\"\n",
        "    prelabel = \"\"\n",
        "    # Removing the first and last tokens\n",
        "    bert_tokens, tag_seqs[0] = bert_tokens[1:-1],tag_seqs[0][1:-1]\n",
        "    for tok,tag in zip(bert_tokens,tag_seqs[0]):\n",
        "      if tok.startswith(\"##\"):\n",
        "          pretok_sent += tok[2:]\n",
        "          prelabel +=str(tag)\n",
        "      else:\n",
        "          pretok_sent += \" \" + tok\n",
        "          prelabel += \" \" + str(tag)\n",
        "    \n",
        "    original_tokens = [tok for tok in word_tokenize(pretok_sent)]\n",
        "    predicted_labels = [tok for tok in word_tokenize(prelabel)]\n",
        "\n",
        "    predicted_entities = []\n",
        "    for tok,tag in zip(original_tokens,predicted_labels):\n",
        "      # print(tok,tag)\n",
        "      if (str(tag2idx['B-Algo']) in tag or str(tag2idx['I-Algo']) in tag):\n",
        "        if len(tok)>1 and tok.isdigit()==False:\n",
        "          predicted_entities.append(tok)\n",
        "    # print(sentence)\n",
        "    # print(predicted_entities)\n",
        "    return predicted_entities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "50b5a9f8e44e4884b8b6089bd4724a7c",
            "18fbe0e697a84bacbabe59f56fe08cdc",
            "300daeff2eae4a5294fb2029d2bb1aff",
            "a50a4eecfc464f03b6a11d0866c53717",
            "0a48f4747d9748858f085f2bbc15b568",
            "50a535fa160347c78ce551f1432680d8",
            "64fe645ab9e048df8a7cf804b54208ca",
            "2aacca41c2424b829ee99a840866a891",
            "a994655fba9e46d099efb4dd1c555eef",
            "b6af30d704554d3080711804437914f3",
            "0daaaae9ee17408caae74c590a987cfe",
            "2ecd58ea81a94c34bb0d0af03b012758",
            "bcc5abeaf78642659ceca109bfc7451f",
            "3ab8b0652dbb4d61b1d2756410fd8ce5",
            "1e20e2c003444fad999c2dc2377e4455",
            "7027ed5dc24e4e73a945c5950abdfaca",
            "535a7a7d16d74a75b2b0c6e86f6a0a61",
            "442d333125834c53a48e894d5d6629e9",
            "33d06719a10842468ecc133481f16ad4",
            "b3706887119d47afa669db636ffbb890",
            "40435075b3c144e298118083b9258d86",
            "b70fe2842a2340b3b8272ef1d405cc82",
            "3c60e253bd85445c9938670a5ec74a9a",
            "43c43ead98244ced8f3b14025dbef6a5",
            "e27d7ca11e9c4373b24cef159438de29",
            "989f543e3ca64800b6c316fc3b165a96",
            "4b916a96ceb8482eaa28855ef5ef9be0",
            "5559d9d88faf4d4980b653ba3df34e7f",
            "e8019898d9414659a2203a8051e1469c",
            "726b86e0fc2f41138345c7ffa90b3cbb",
            "43a851b294ca42e7845892a429df2957",
            "cd1cc10fd827416fb98613e874913808",
            "48c262b5fa02432c8abbd1aec2e9a53b"
          ]
        },
        "id": "13iFf2IQZ_wK",
        "outputId": "09d2e8b6-f96c-47e4-bc3e-da9103a1c615"
      },
      "source": [
        "bert_model = 'allenai/scibert_scivocab_uncased'\n",
        "with open('/content/drive/MyDrive/models/model_algo/tag2idx.pkl','rb') as f:\n",
        "  tag2idx = pickle.load(f)\n",
        "# checkpt = torch.load('/content/drive/MyDrive/models/model_algo/model_0.pt',map_location=torch.device('cpu'))\n",
        "checkpt = torch.load('/content/drive/MyDrive/models/model_scibert_paperswithcode/model/model_0.pt',map_location=torch.device('cpu'))\n",
        "scibertmodel = Bert_CRF.from_pretrained(bert_model, num_labels = len(tag2idx))\n",
        "scibertmodel.to(device)\n",
        "scibertmodel.load_state_dict(checkpt['model_state_dict'],strict = False)\n",
        "get_algo_entities('implement strong baselines with features available in FiCLS, including GLU (Hadiwinoto et al., 2019), GlossBERT (Huang et al., 2019) and BEM (Blevins and Zettlemoyer, 2020), and use the same settings as our model for a fair comparison.',scibertmodel)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50b5a9f8e44e4884b8b6089bd4724a7c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ecd58ea81a94c34bb0d0af03b012758",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/422M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at allenai/scibert_scivocab_uncased were not used when initializing Bert_CRF: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing Bert_CRF from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing Bert_CRF from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of Bert_CRF were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['crf.start_transitions', 'classifier.bias', 'crf.end_transitions', 'crf.transitions', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c60e253bd85445c9938670a5ec74a9a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/223k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchcrf/__init__.py:305: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ../aten/src/ATen/native/TensorCompare.cpp:328.)\n",
            "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['baselines', 'ficls', 'glossbert', 'bem', 'model']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsXnnbzla1Ex"
      },
      "source": [
        "## Keyphrase Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qb5QDmnL15kR"
      },
      "source": [
        "!python -m nltk.downloader stopwords\n",
        "!python -m nltk.downloader universal_tagset\n",
        "!python -m spacy download en # download the english model\n",
        "!pip install git+https://github.com/boudinfl/pke.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAfYsVBXa4tM"
      },
      "source": [
        "import pke\n",
        "import string\n",
        "def get_keyphrases(text = \"abcd efg hijk I am this\"):\n",
        "  extractor = pke.unsupervised.MultipartiteRank()\n",
        "  extractor.load_document(input=text)\n",
        "  pos = {'NOUN', 'PROPN', 'ADJ'}\n",
        "  stoplist = list(string.punctuation)\n",
        "  stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
        "  stoplist += stopwords.words('english')\n",
        "  extractor.candidate_selection(pos=pos, stoplist=stoplist)\n",
        "  extractor.candidate_weighting(alpha=1.1,\n",
        "                                threshold=0.74,\n",
        "                                method='average')\n",
        "  keyphrases = extractor.get_n_best(n=1000)\n",
        "  return keyphrases"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3TSXol-d0j0",
        "outputId": "233231a5-140e-474b-c75c-3cb901270e72"
      },
      "source": [
        "import pke\n",
        "def get_keyphrases(text = \"abcd efg hijk I am this\"):\n",
        "  # TextRank\n",
        "\n",
        "  # define the set of valid Part-of-Speeches\n",
        "  pos = {'NOUN', 'PROPN', 'ADJ'}\n",
        "\n",
        "  # 1. create a TextRank extractor.\n",
        "  extractor = pke.unsupervised.TextRank()\n",
        "\n",
        "  # 2. load the content of the document.\n",
        "  extractor.load_document(input=text\n",
        "                          )\n",
        "\n",
        "  # 3. build the graph representation of the document and rank the words.\n",
        "  #    Keyphrase candidates are composed from the 33-percent\n",
        "  #    highest-ranked words.\n",
        "  extractor.candidate_weighting(window=2,\n",
        "                                pos=pos,\n",
        "                                top_percent = 0.8\n",
        "                                )\n",
        "\n",
        "  # 4. get the 10-highest scored candidates as keyphrases\n",
        "  keyphrases = extractor.get_n_best(n=1000)\n",
        "  return keyphrases\n",
        "########################################################### Single Rank #####################\n",
        "# import pke\n",
        "# def get_keyphrases(text = \"abcd efg hijk I am this\"):\n",
        "#   # define the set of valid Part-of-Speeches\n",
        "#   pos = {'NOUN', 'PROPN', 'ADJ'}\n",
        "\n",
        "#   # 1. create a SingleRank extractor.\n",
        "#   extractor = pke.unsupervised.SingleRank()\n",
        "\n",
        "#   # 2. load the content of the document.\n",
        "#   extractor.load_document(input=text,\n",
        "#                           language='en',\n",
        "#                           normalization=None)\n",
        "\n",
        "#   # 3. select the longest sequences of nouns and adjectives as candidates.\n",
        "#   extractor.candidate_selection(pos=pos)\n",
        "\n",
        "#   # 4. weight the candidates using the sum of their word's scores that are\n",
        "#   #    computed using random walk. In the graph, nodes are words of\n",
        "#   #    certain part-of-speech (nouns and adjectives) that are connected if\n",
        "#   #    they occur in a window of 10 words.\n",
        "#   extractor.candidate_weighting(window=10,\n",
        "#                                 pos=pos)\n",
        "\n",
        "#   # 5. get the 10-highest scored candidates as keyphrases\n",
        "#   keyphrases = extractor.get_n_best(n=1000)\n",
        "#   return keyphrases\n",
        "\n",
        "# ################################ TopicRank ##############################\n",
        "# import pke\n",
        "# import string\n",
        "# from nltk.corpus import stopwords\n",
        "# def get_keyphrases(text = \"abcd efg hijk I am this\"):\n",
        "#   # 1. create a TopicRank extractor.\n",
        "#   extractor = pke.unsupervised.TopicRank()\n",
        "\n",
        "#   # 2. load the content of the document.\n",
        "#   extractor.load_document(input=text)\n",
        "\n",
        "#   # 3. select the longest sequences of nouns and adjectives, that do\n",
        "#   #    not contain punctuation marks or stopwords as candidates.\n",
        "#   pos = {'NOUN', 'PROPN', 'ADJ'}\n",
        "#   stoplist = list(string.punctuation)\n",
        "#   stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
        "#   stoplist += stopwords.words('english')\n",
        "#   extractor.candidate_selection(pos=pos, stoplist=stoplist)\n",
        "\n",
        "#   # 4. build topics by grouping candidates with HAC (average linkage,\n",
        "#   #    threshold of 1/4 of shared stems). Weight the topics using random\n",
        "#   #    walk, and select the first occuring candidate from each topic.\n",
        "#   extractor.candidate_weighting(threshold=0.74, method='average')\n",
        "\n",
        "#   # 5. get the 10-highest scored candidates as keyphrases\n",
        "#   keyphrases = extractor.get_n_best(n=1000)\n",
        "#   return keyphrases\n",
        "\n",
        "# ########################## PositionRank ##################################\n",
        "# import pke\n",
        "\n",
        "# def get_keyphrases(text = \"abcd efg hijk I am this\"):\n",
        "#   # define the valid Part-of-Speeches to occur in the graph\n",
        "#   pos = {'NOUN', 'PROPN', 'ADJ'}\n",
        "\n",
        "#   # define the grammar for selecting the keyphrase candidates\n",
        "#   grammar = \"NP: {<ADJ>*<NOUN|PROPN>+}\"\n",
        "\n",
        "#   # 1. create a PositionRank extractor.\n",
        "#   extractor = pke.unsupervised.PositionRank()\n",
        "\n",
        "#   # 2. load the content of the document.\n",
        "#   extractor.load_document(input=text,\n",
        "#                           language='en',\n",
        "#                           normalization=None)\n",
        "\n",
        "#   # 3. select the noun phrases up to 3 words as keyphrase candidates.\n",
        "#   extractor.candidate_selection(grammar=grammar,\n",
        "#                                 maximum_word_number=3)\n",
        "\n",
        "#   # 4. weight the candidates using the sum of their word's scores that are\n",
        "#   #    computed using random walk biaised with the position of the words\n",
        "#   #    in the document. In the graph, nodes are words (nouns and\n",
        "#   #    adjectives only) that are connected if they occur in a window of\n",
        "#   #    10 words.\n",
        "#   extractor.candidate_weighting(window=10,\n",
        "#                                 pos=pos)\n",
        "\n",
        "#   # 5. get the 10-highest scored candidates as keyphrases\n",
        "#   keyphrases = extractor.get_n_best(n=1000)\n",
        "#   return keyphrases\n",
        "\n",
        "get_keyphrases('''In this paper, we propose a novel embedding\n",
        "model, named ConvKB, for knowledge base\n",
        "completion. Our model ConvKB advances\n",
        "state-of-the-art models by employing a convo\u0002lutional neural network, so that it can capture\n",
        "global relationships and transitional character\u0002istics between entities and relations in knowl\u0002edge bases. In ConvKB, each triple (head en\u0002tity, relation, tail entity) is represented as a 3-\n",
        "column matrix where each column vector rep\u0002resents a triple element. This 3-column matrix\n",
        "is then fed to a convolution layer where multi\u0002ple filters are operated on the matrix to gener\u0002ate different feature maps. These feature maps\n",
        "are then concatenated into a single feature vec\u0002tor representing the input triple. The feature\n",
        "vector is multiplied with a weight vector via\n",
        "a dot product to return a score. This score\n",
        "is then used to predict whether the triple is\n",
        "valid or not. Experiments show that ConvKB\n",
        "achieves better link prediction performance\n",
        "than previous state-of-the-art embedding mod\u0002els on two benchmark datasets WN18RR and\n",
        "FB15k-237.'''\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('better link prediction performance', 0.08447905672650476),\n",
              " ('different feature maps', 0.07769642479523654),\n",
              " ('art embedding mod\\x02els', 0.06545816355841445),\n",
              " ('feature maps', 0.06374581673878935),\n",
              " ('benchmark datasets wn18rr', 0.06335991254487858),\n",
              " ('convo\\x02lutional neural network', 0.06335834254487857),\n",
              " ('column vector', 0.05483697997050867),\n",
              " ('art models', 0.05121468114044349),\n",
              " ('feature', 0.049795248682342155),\n",
              " ('input triple', 0.04701905911337171),\n",
              " ('triple element', 0.04701863911337171),\n",
              " ('knowl\\x02edge bases', 0.047018329113371705),\n",
              " ('knowledge base', 0.047017919113371706),\n",
              " ('previous state', 0.04224046836325237),\n",
              " ('dot product', 0.04224010836325237),\n",
              " ('weight vector', 0.04224005836325238),\n",
              " ('multi\\x02ple filters', 0.04223967836325237),\n",
              " ('convolution layer', 0.04223964836325237),\n",
              " ('column matrix', 0.04223944836325238),\n",
              " ('tail entity', 0.04223935836325237),\n",
              " ('head en\\x02tity', 0.04223930836325237),\n",
              " ('transitional character\\x02istics', 0.04223914836325237),\n",
              " ('global relationships', 0.04223911836325237),\n",
              " ('model convkb', 0.040140567349716466),\n",
              " ('triple', 0.030678185681864843),\n",
              " ('predict', 0.027419669985254334),\n",
              " ('vector', 0.02741942998525433),\n",
              " ('model', 0.025898534931745508),\n",
              " ('embedding', 0.025898514931745508),\n",
              " ('entities', 0.021119854181626183),\n",
              " ('state', 0.021119584181626183),\n",
              " ('matrix', 0.014821508377998043),\n",
              " ('convkb', 0.014242042417970956)]"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSQOZXc2a6dz"
      },
      "source": [
        "## Execute Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKVn0Q1la-xc"
      },
      "source": [
        "def execute_pipeline(citation_sentences,scibertmodel):\n",
        "    ##Getting named entities from citation sentences (sequence labeller)\n",
        "    ents = set()\n",
        "    for s in citation_sentences:\n",
        "        entity = get_algo_entities(s,scibertmodel)\n",
        "        ents.update(entity)\n",
        "\n",
        "    temp_ents = list(ents)\n",
        "    for word in ents:\n",
        "      if word[-1] == 's' and word[:-1] in ents:    #Removing plural duplicates of words \n",
        "        temp_ents.remove(word)\n",
        "    ents = temp_ents\n",
        "    predicted_algos = ents\n",
        "    ########## Keyphrase ##############################\n",
        "    words = []\n",
        "    for sentence in citation_sentences:\n",
        "      for word,pos in pos_tag([w for w in word_tokenize(sentence) if w not in stop]):\n",
        "          if pos == 'NNP':\n",
        "            if '-' in word and word[word.index('-')+1].isupper():\n",
        "              word = word.replace('-','')\n",
        "          words.append(word)\n",
        "    citationtext = \" \".join(words)\n",
        "    keyphrases = get_keyphrases(citationtext)\n",
        "    keyphrases = [k.replace('-','') for k,s in keyphrases[:len(keyphrases)] if len(k)<=15 and len(word_tokenize(k))<=2]\n",
        "    # print(keyphrases)\n",
        "    # for word in keyphrases:\n",
        "    #   if word[-1] == 's' and word[:-1] in ents:    #Removing plural duplicates of words \n",
        "    #     keyphrases.remove(word)\n",
        "    \n",
        "    ####################################################\n",
        "    predicted_algos = [ent for ent in keyphrases if ent in predicted_algos]\n",
        "    return keyphrases,predicted_algos\n",
        "    # return predicted_algos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOhUt0kVmbHO"
      },
      "source": [
        "## Extracting Entities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4rMIvtenvYe"
      },
      "source": [
        "!unzip citation_sentences.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09X6MdKl1YoG",
        "outputId": "2458659d-820e-4e07-bdd8-50f0687d19ae"
      },
      "source": [
        "!mkdir 'output'\n",
        "%cd output\n",
        "!mkdir 'keyphrase'\n",
        "!mkdir 'final output'\n",
        "%cd ../"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/output\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGgR6FJ2mdt8",
        "outputId": "2ecddd59-088b-440a-c47c-f3be45f298ec"
      },
      "source": [
        "parentdir = '.'\n",
        "citdir = \"citation_sentences\"\n",
        "outputdir = 'output'\n",
        "inputfolder = join(parentdir, citdir)\n",
        "outputfolder = join(parentdir, outputdir)\n",
        "\n",
        "fileslist = [f for f in listdir(inputfolder) if isfile(\n",
        "        join(inputfolder, f))]\n",
        "fileslist.sort()\n",
        "\n",
        "for i,filename in tqdm(enumerate(fileslist), total=len(fileslist)):\n",
        "  print(filename)\n",
        "  citation_sentences =  []\n",
        "  with open(inputfolder+'/'+filename) as f:\n",
        "    for line in f:\n",
        "      if line[0] == '[':\n",
        "        continue\n",
        "      citation_sentences.append(line.strip(\"\\n\"))\n",
        "  keyphrases, final_predicted = execute_pipeline(citation_sentences,scibertmodel)\n",
        "  with open(outputfolder+\"/\" + \"keyphrase\" +\"/\"+filename, 'w',encoding = 'utf-8') as f:\n",
        "    for ent in keyphrases:\n",
        "      f.write(ent+\"\\n\")\n",
        "  with open(outputfolder+\"/\" + \"final output\" +\"/\"+filename, 'w',encoding = 'utf-8') as f:\n",
        "    for ent in final_predicted:\n",
        "      f.write(ent+\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/84 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1909.00426.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            "  1%|          | 1/84 [00:20<28:24, 20.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1909.08402v1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            "  2%|▏         | 2/84 [00:37<25:01, 18.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1911.00219v3.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            "  4%|▎         | 3/84 [00:38<14:28, 10.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1911.09419v2.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            "  5%|▍         | 4/84 [00:47<12:56,  9.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2004.05150v2.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            "  6%|▌         | 5/84 [01:36<31:38, 24.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2005.00545v1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            "  7%|▋         | 6/84 [02:01<31:47, 24.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2005.00702.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            "  8%|▊         | 7/84 [02:41<37:52, 29.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2009.12517v1.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 10%|▉         | 8/84 [03:26<43:38, 34.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2010.01057.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 11%|█         | 9/84 [04:18<49:37, 39.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020.acl-main.195.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 12%|█▏        | 10/84 [04:48<45:27, 36.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020.acl-main.209.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 13%|█▎        | 11/84 [05:04<36:54, 30.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020.acl-main.29.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 14%|█▍        | 12/84 [05:44<40:11, 33.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020.acl-main.748.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 15%|█▌        | 13/84 [06:20<40:35, 34.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020.emnlp-main.460.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 17%|█▋        | 14/84 [07:21<49:18, 42.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2020.emnlp-main.523.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 18%|█▊        | 15/84 [08:12<51:44, 45.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.acl-long.336.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 19%|█▉        | 16/84 [08:49<48:13, 42.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.eacl-demos.4.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 20%|██        | 17/84 [09:12<40:55, 36.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.findings-emnlp.23.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 21%|██▏       | 18/84 [09:31<34:30, 31.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.findings-emnlp.4.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 23%|██▎       | 19/84 [09:49<29:36, 27.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.findings-emnlp.47.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 24%|██▍       | 20/84 [10:13<28:08, 26.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.findings-emnlp.48.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 25%|██▌       | 21/84 [10:30<24:36, 23.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.findings-emnlp.50.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 26%|██▌       | 22/84 [10:46<21:48, 21.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.findings-emnlp.53.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 27%|██▋       | 23/84 [11:09<22:14, 21.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.findings-emnlp.54.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 29%|██▊       | 24/84 [11:28<20:52, 20.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.findings-emnlp.58.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 30%|██▉       | 25/84 [11:36<16:53, 17.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.findings-emnlp.63.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 31%|███       | 26/84 [11:57<17:37, 18.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.findings-emnlp.67.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 32%|███▏      | 27/84 [12:20<18:35, 19.56s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.findings-emnlp.77.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 33%|███▎      | 28/84 [12:37<17:34, 18.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.findings-emnlp.78.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 35%|███▍      | 29/84 [12:57<17:43, 19.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.findings-emnlp.80.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 36%|███▌      | 30/84 [13:10<15:35, 17.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.findings-emnlp.87.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 37%|███▋      | 31/84 [13:26<14:58, 16.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.findings-emnlp.90.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 38%|███▊      | 32/84 [13:48<15:54, 18.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.mrl-1.2.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 39%|███▉      | 33/84 [13:48<11:05, 13.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.naacl-main.187.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 40%|████      | 34/84 [14:22<15:54, 19.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021.naacl-main.41.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 42%|████▏     | 35/84 [14:22<11:05, 13.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2104.07190.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 43%|████▎     | 36/84 [14:38<11:20, 14.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2109.05782.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 44%|████▍     | 37/84 [15:01<13:09, 16.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2110.00423.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 45%|████▌     | 38/84 [15:14<12:07, 15.81s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3459637.3482113.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 46%|████▋     | 39/84 [15:46<15:23, 20.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5067-Article Text-8130-1-10-20190709.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 48%|████▊     | 40/84 [15:46<10:38, 14.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Benchmarking Study of Embedding based entity alignment for Knowledge Graphs (Springer).txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 49%|████▉     | 41/84 [16:42<19:11, 26.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A Proximity Weighted Evidential k.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 50%|█████     | 42/84 [16:56<16:11, 23.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "An Improved Proportionate Normalized.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 51%|█████     | 43/84 [16:57<11:10, 16.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AutoSUM - Automating Feature Extraction.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 52%|█████▏    | 44/84 [17:25<13:18, 19.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BiWalkLDA.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 54%|█████▎    | 45/84 [17:50<13:50, 21.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bottom-Up and Top-Down Graph Pooling.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 55%|█████▍    | 46/84 [18:12<13:44, 21.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CACRNN- A Context-Aware.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 56%|█████▌    | 47/84 [18:27<12:00, 19.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLINE.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 57%|█████▋    | 48/84 [19:07<15:27, 25.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chinese Sentence Semantic Matching.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 58%|█████▊    | 49/84 [19:27<13:56, 23.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation-aware Deep Generative Model for.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 60%|█████▉    | 50/84 [19:45<12:34, 22.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CrowdQM- Learning Aspect-Level User.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 61%|██████    | 51/84 [20:04<11:44, 21.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CubeFlow.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 62%|██████▏   | 52/84 [20:18<10:12, 19.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DELAFO.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 63%|██████▎   | 53/84 [20:33<09:14, 17.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DOLORES Deep Contextualized Knowledge Graph Embeddings.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 64%|██████▍   | 54/84 [21:11<11:52, 23.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deep Cost-Sensitive Kernel Machine for.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 65%|██████▌   | 55/84 [21:26<10:19, 21.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GAMMA-A Graph and Multi-view.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 67%|██████▋   | 56/84 [21:57<11:17, 24.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JARKA.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 68%|██████▊   | 57/84 [22:12<09:34, 21.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Joint Relational Dependency Learning.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 69%|██████▉   | 58/84 [22:35<09:26, 21.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KBGAN.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 70%|███████   | 59/84 [23:04<09:57, 23.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LoPAD.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 71%|███████▏  | 60/84 [23:27<09:32, 23.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mask-Guided Region Attention Network.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 73%|███████▎  | 61/84 [23:42<08:07, 21.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiple Demographic Attributes.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 74%|███████▍  | 62/84 [23:58<07:10, 19.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N18-1133.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 75%|███████▌  | 63/84 [23:59<04:51, 13.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N19-1286.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 76%|███████▌  | 64/84 [24:24<05:48, 17.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NoALgo.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 77%|███████▋  | 65/84 [24:42<05:34, 17.60s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P19-1466.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 79%|███████▊  | 66/84 [25:14<06:30, 21.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Passenger demand forecasting with multi-task convolutional recurrent neural networks (accepted version).txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 80%|███████▉  | 67/84 [25:34<06:00, 21.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relation Embedding for Personalised.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 81%|████████  | 68/84 [25:51<05:21, 20.07s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Robust Attribute and Structure.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 82%|████████▏ | 69/84 [26:23<05:55, 23.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rotate.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 83%|████████▎ | 70/84 [27:13<07:21, 31.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SCIBERT.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 85%|████████▍ | 71/84 [27:47<06:59, 32.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SGCN-A Graph Sparsifier.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 86%|████████▌ | 72/84 [28:05<05:36, 28.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SLGAT-Soft Labels Guided Graph.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 87%|████████▋ | 73/84 [28:37<05:20, 29.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SoRecGAT- Leveraging Graph Attention.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 88%|████████▊ | 74/84 [29:07<04:53, 29.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SubRank-Subgraph Embeddings.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 89%|████████▉ | 75/84 [29:31<04:09, 27.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TemporalGAT.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 90%|█████████ | 76/84 [29:54<03:30, 26.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Towards Understanding Transfer Learning.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 92%|█████████▏| 77/84 [30:13<02:48, 24.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransG.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 93%|█████████▎| 78/84 [30:35<02:21, 23.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsupervised Boosting-based Autoencoder Ensembles for Outlier Detection.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 94%|█████████▍| 79/84 [30:55<01:52, 22.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deberta_decoding_enhanced_bert.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 95%|█████████▌| 80/84 [31:49<02:07, 31.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "euphemistic.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 96%|█████████▋| 81/84 [32:17<01:32, 30.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "new.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 98%|█████████▊| 82/84 [32:30<00:50, 25.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "p1877.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            " 99%|█████████▉| 83/84 [32:31<00:18, 18.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "you_can_teach_an_old_dog_new_t.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Candidates are generated using 0.8-top\n",
            "100%|██████████| 84/84 [33:04<00:00, 23.63s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BclyA2dEl54K",
        "outputId": "279c131b-e634-4519-f437-25741a095667"
      },
      "source": [
        "final_predicted"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['word entity', 'et al', 'mentions entity'], [])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMmpBzjXJvC5",
        "outputId": "b93f3bf5-d1fa-4e13-9b9f-3dc65f79587f"
      },
      "source": [
        "!zip -r output.zip output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: output/ (stored 0%)\n",
            "  adding: output/keyphrase/ (stored 0%)\n",
            "  adding: output/keyphrase/1911.09419v2.txt (deflated 18%)\n",
            "  adding: output/keyphrase/CLINE.txt (deflated 46%)\n",
            "  adding: output/keyphrase/2021.eacl-demos.4.txt (deflated 41%)\n",
            "  adding: output/keyphrase/2109.05782.txt (deflated 32%)\n",
            "  adding: output/keyphrase/2021.findings-emnlp.50.txt (deflated 34%)\n",
            "  adding: output/keyphrase/2021.findings-emnlp.63.txt (deflated 40%)\n",
            "  adding: output/keyphrase/2021.findings-emnlp.23.txt (deflated 34%)\n",
            "  adding: output/keyphrase/2021.findings-emnlp.54.txt (deflated 40%)\n",
            "  adding: output/keyphrase/TransG.txt (deflated 24%)\n",
            "  adding: output/keyphrase/LoPAD.txt (deflated 39%)\n",
            "  adding: output/keyphrase/2021.naacl-main.41.txt (stored 0%)\n",
            "  adding: output/keyphrase/Mask-Guided Region Attention Network.txt (deflated 32%)\n",
            "  adding: output/keyphrase/DOLORES Deep Contextualized Knowledge Graph Embeddings.txt (deflated 44%)\n",
            "  adding: output/keyphrase/SLGAT-Soft Labels Guided Graph.txt (deflated 37%)\n",
            "  adding: output/keyphrase/you_can_teach_an_old_dog_new_t.txt (deflated 43%)\n",
            "  adding: output/keyphrase/Chinese Sentence Semantic Matching.txt (deflated 21%)\n",
            "  adding: output/keyphrase/Rotate.txt (deflated 41%)\n",
            "  adding: output/keyphrase/Multiple Demographic Attributes.txt (deflated 28%)\n",
            "  adding: output/keyphrase/TemporalGAT.txt (deflated 37%)\n",
            "  adding: output/keyphrase/AutoSUM - Automating Feature Extraction.txt (deflated 39%)\n",
            "  adding: output/keyphrase/2021.findings-emnlp.58.txt (deflated 24%)\n",
            "  adding: output/keyphrase/3459637.3482113.txt (deflated 37%)\n",
            "  adding: output/keyphrase/2020.acl-main.209.txt (deflated 38%)\n",
            "  adding: output/keyphrase/GAMMA-A Graph and Multi-view.txt (deflated 31%)\n",
            "  adding: output/keyphrase/1911.00219v3.txt (stored 0%)\n",
            "  adding: output/keyphrase/Unsupervised Boosting-based Autoencoder Ensembles for Outlier Detection.txt (deflated 33%)\n",
            "  adding: output/keyphrase/Passenger demand forecasting with multi-task convolutional recurrent neural networks (accepted version).txt (deflated 37%)\n",
            "  adding: output/keyphrase/2020.acl-main.748.txt (deflated 39%)\n",
            "  adding: output/keyphrase/2021.findings-emnlp.53.txt (deflated 33%)\n",
            "  adding: output/keyphrase/Joint Relational Dependency Learning.txt (deflated 33%)\n",
            "  adding: output/keyphrase/BiWalkLDA.txt (deflated 33%)\n",
            "  adding: output/keyphrase/deberta_decoding_enhanced_bert.txt (deflated 39%)\n",
            "  adding: output/keyphrase/Deep Cost-Sensitive Kernel Machine for.txt (deflated 1%)\n",
            "  adding: output/keyphrase/SubRank-Subgraph Embeddings.txt (deflated 30%)\n",
            "  adding: output/keyphrase/Correlation-aware Deep Generative Model for.txt (deflated 37%)\n",
            "  adding: output/keyphrase/2021.mrl-1.2.txt (stored 0%)\n",
            "  adding: output/keyphrase/2020.emnlp-main.523.txt (deflated 48%)\n",
            "  adding: output/keyphrase/CubeFlow.txt (deflated 31%)\n",
            "  adding: output/keyphrase/2020.acl-main.29.txt (deflated 40%)\n",
            "  adding: output/keyphrase/JARKA.txt (deflated 21%)\n",
            "  adding: output/keyphrase/2104.07190.txt (deflated 35%)\n",
            "  adding: output/keyphrase/CACRNN- A Context-Aware.txt (deflated 19%)\n",
            "  adding: output/keyphrase/2021.findings-emnlp.87.txt (deflated 32%)\n",
            "  adding: output/keyphrase/Bottom-Up and Top-Down Graph Pooling.txt (deflated 40%)\n",
            "  adding: output/keyphrase/2004.05150v2.txt (deflated 46%)\n",
            "  adding: output/keyphrase/euphemistic.txt (deflated 37%)\n",
            "  adding: output/keyphrase/Robust Attribute and Structure.txt (deflated 24%)\n",
            "  adding: output/keyphrase/Towards Understanding Transfer Learning.txt (deflated 30%)\n",
            "  adding: output/keyphrase/2021.findings-emnlp.90.txt (deflated 37%)\n",
            "  adding: output/keyphrase/SoRecGAT- Leveraging Graph Attention.txt (deflated 34%)\n",
            "  adding: output/keyphrase/2021.findings-emnlp.48.txt (deflated 30%)\n",
            "  adding: output/keyphrase/2021.findings-emnlp.47.txt (deflated 39%)\n",
            "  adding: output/keyphrase/N18-1133.txt (stored 0%)\n",
            "  adding: output/keyphrase/A Benchmarking Study of Embedding based entity alignment for Knowledge Graphs (Springer).txt (deflated 38%)\n",
            "  adding: output/keyphrase/2021.findings-emnlp.4.txt (deflated 38%)\n",
            "  adding: output/keyphrase/2010.01057.txt (deflated 48%)\n",
            "  adding: output/keyphrase/SCIBERT.txt (deflated 40%)\n",
            "  adding: output/keyphrase/2020.emnlp-main.460.txt (deflated 37%)\n",
            "  adding: output/keyphrase/2020.acl-main.195.txt (deflated 35%)\n",
            "  adding: output/keyphrase/KBGAN.txt (deflated 33%)\n",
            "  adding: output/keyphrase/1909.00426.txt (deflated 39%)\n",
            "  adding: output/keyphrase/2110.00423.txt (deflated 23%)\n",
            "  adding: output/keyphrase/Relation Embedding for Personalised.txt (deflated 35%)\n",
            "  adding: output/keyphrase/N19-1286.txt (deflated 42%)\n",
            "  adding: output/keyphrase/2021.naacl-main.187.txt (deflated 41%)\n",
            "  adding: output/keyphrase/SGCN-A Graph Sparsifier.txt (deflated 33%)\n",
            "  adding: output/keyphrase/A Proximity Weighted Evidential k.txt (deflated 27%)\n",
            "  adding: output/keyphrase/2009.12517v1.txt (deflated 46%)\n",
            "  adding: output/keyphrase/2005.00545v1.txt (deflated 37%)\n",
            "  adding: output/keyphrase/2021.findings-emnlp.80.txt (deflated 23%)\n",
            "  adding: output/keyphrase/DELAFO.txt (deflated 30%)\n",
            "  adding: output/keyphrase/p1877.txt (stored 0%)\n",
            "  adding: output/keyphrase/2021.findings-emnlp.78.txt (deflated 29%)\n",
            "  adding: output/keyphrase/new.txt (deflated 28%)\n",
            "  adding: output/keyphrase/2005.00702.txt (deflated 41%)\n",
            "  adding: output/keyphrase/2021.acl-long.336.txt (deflated 35%)\n",
            "  adding: output/keyphrase/2021.findings-emnlp.77.txt (deflated 23%)\n",
            "  adding: output/keyphrase/1909.08402v1.txt (deflated 27%)\n",
            "  adding: output/keyphrase/CrowdQM- Learning Aspect-Level User.txt (deflated 31%)\n",
            "  adding: output/keyphrase/An Improved Proportionate Normalized.txt (stored 0%)\n",
            "  adding: output/keyphrase/P19-1466.txt (deflated 38%)\n",
            "  adding: output/keyphrase/5067-Article Text-8130-1-10-20190709.txt (stored 0%)\n",
            "  adding: output/keyphrase/NoALgo.txt (deflated 31%)\n",
            "  adding: output/keyphrase/2021.findings-emnlp.67.txt (deflated 33%)\n",
            "  adding: output/final output/ (stored 0%)\n",
            "  adding: output/final output/1911.09419v2.txt (stored 0%)\n",
            "  adding: output/final output/CLINE.txt (deflated 6%)\n",
            "  adding: output/final output/2021.eacl-demos.4.txt (stored 0%)\n",
            "  adding: output/final output/2109.05782.txt (stored 0%)\n",
            "  adding: output/final output/2021.findings-emnlp.50.txt (stored 0%)\n",
            "  adding: output/final output/2021.findings-emnlp.63.txt (stored 0%)\n",
            "  adding: output/final output/2021.findings-emnlp.23.txt (stored 0%)\n",
            "  adding: output/final output/2021.findings-emnlp.54.txt (stored 0%)\n",
            "  adding: output/final output/TransG.txt (stored 0%)\n",
            "  adding: output/final output/LoPAD.txt (stored 0%)\n",
            "  adding: output/final output/2021.naacl-main.41.txt (stored 0%)\n",
            "  adding: output/final output/Mask-Guided Region Attention Network.txt (stored 0%)\n",
            "  adding: output/final output/DOLORES Deep Contextualized Knowledge Graph Embeddings.txt (deflated 2%)\n",
            "  adding: output/final output/SLGAT-Soft Labels Guided Graph.txt (deflated 4%)\n",
            "  adding: output/final output/you_can_teach_an_old_dog_new_t.txt (deflated 5%)\n",
            "  adding: output/final output/Chinese Sentence Semantic Matching.txt (stored 0%)\n",
            "  adding: output/final output/Rotate.txt (deflated 10%)\n",
            "  adding: output/final output/Multiple Demographic Attributes.txt (deflated 6%)\n",
            "  adding: output/final output/TemporalGAT.txt (deflated 3%)\n",
            "  adding: output/final output/AutoSUM - Automating Feature Extraction.txt (stored 0%)\n",
            "  adding: output/final output/2021.findings-emnlp.58.txt (stored 0%)\n",
            "  adding: output/final output/3459637.3482113.txt (stored 0%)\n",
            "  adding: output/final output/2020.acl-main.209.txt (stored 0%)\n",
            "  adding: output/final output/GAMMA-A Graph and Multi-view.txt (stored 0%)\n",
            "  adding: output/final output/1911.00219v3.txt (stored 0%)\n",
            "  adding: output/final output/Unsupervised Boosting-based Autoencoder Ensembles for Outlier Detection.txt (stored 0%)\n",
            "  adding: output/final output/Passenger demand forecasting with multi-task convolutional recurrent neural networks (accepted version).txt (stored 0%)\n",
            "  adding: output/final output/2020.acl-main.748.txt (stored 0%)\n",
            "  adding: output/final output/2021.findings-emnlp.53.txt (stored 0%)\n",
            "  adding: output/final output/Joint Relational Dependency Learning.txt (stored 0%)\n",
            "  adding: output/final output/BiWalkLDA.txt (stored 0%)\n",
            "  adding: output/final output/deberta_decoding_enhanced_bert.txt (deflated 2%)\n",
            "  adding: output/final output/Deep Cost-Sensitive Kernel Machine for.txt (stored 0%)\n",
            "  adding: output/final output/SubRank-Subgraph Embeddings.txt (stored 0%)\n",
            "  adding: output/final output/Correlation-aware Deep Generative Model for.txt (deflated 11%)\n",
            "  adding: output/final output/2021.mrl-1.2.txt (stored 0%)\n",
            "  adding: output/final output/2020.emnlp-main.523.txt (deflated 18%)\n",
            "  adding: output/final output/CubeFlow.txt (stored 0%)\n",
            "  adding: output/final output/2020.acl-main.29.txt (deflated 11%)\n",
            "  adding: output/final output/JARKA.txt (stored 0%)\n",
            "  adding: output/final output/2104.07190.txt (stored 0%)\n",
            "  adding: output/final output/CACRNN- A Context-Aware.txt (stored 0%)\n",
            "  adding: output/final output/2021.findings-emnlp.87.txt (stored 0%)\n",
            "  adding: output/final output/Bottom-Up and Top-Down Graph Pooling.txt (stored 0%)\n",
            "  adding: output/final output/2004.05150v2.txt (deflated 27%)\n",
            "  adding: output/final output/euphemistic.txt (deflated 2%)\n",
            "  adding: output/final output/Robust Attribute and Structure.txt (stored 0%)\n",
            "  adding: output/final output/Towards Understanding Transfer Learning.txt (stored 0%)\n",
            "  adding: output/final output/2021.findings-emnlp.90.txt (stored 0%)\n",
            "  adding: output/final output/SoRecGAT- Leveraging Graph Attention.txt (stored 0%)\n",
            "  adding: output/final output/2021.findings-emnlp.48.txt (stored 0%)\n",
            "  adding: output/final output/2021.findings-emnlp.47.txt (stored 0%)\n",
            "  adding: output/final output/N18-1133.txt (stored 0%)\n",
            "  adding: output/final output/A Benchmarking Study of Embedding based entity alignment for Knowledge Graphs (Springer).txt (deflated 9%)\n",
            "  adding: output/final output/2021.findings-emnlp.4.txt (stored 0%)\n",
            "  adding: output/final output/2010.01057.txt (deflated 18%)\n",
            "  adding: output/final output/SCIBERT.txt (deflated 13%)\n",
            "  adding: output/final output/2020.emnlp-main.460.txt (deflated 15%)\n",
            "  adding: output/final output/2020.acl-main.195.txt (stored 0%)\n",
            "  adding: output/final output/KBGAN.txt (stored 0%)\n",
            "  adding: output/final output/1909.00426.txt (stored 0%)\n",
            "  adding: output/final output/2110.00423.txt (stored 0%)\n",
            "  adding: output/final output/Relation Embedding for Personalised.txt (stored 0%)\n",
            "  adding: output/final output/N19-1286.txt (stored 0%)\n",
            "  adding: output/final output/2021.naacl-main.187.txt (stored 0%)\n",
            "  adding: output/final output/SGCN-A Graph Sparsifier.txt (stored 0%)\n",
            "  adding: output/final output/A Proximity Weighted Evidential k.txt (stored 0%)\n",
            "  adding: output/final output/2009.12517v1.txt (deflated 10%)\n",
            "  adding: output/final output/2005.00545v1.txt (stored 0%)\n",
            "  adding: output/final output/2021.findings-emnlp.80.txt (stored 0%)\n",
            "  adding: output/final output/DELAFO.txt (stored 0%)\n",
            "  adding: output/final output/p1877.txt (stored 0%)\n",
            "  adding: output/final output/2021.findings-emnlp.78.txt (stored 0%)\n",
            "  adding: output/final output/new.txt (stored 0%)\n",
            "  adding: output/final output/2005.00702.txt (stored 0%)\n",
            "  adding: output/final output/2021.acl-long.336.txt (deflated 8%)\n",
            "  adding: output/final output/2021.findings-emnlp.77.txt (stored 0%)\n",
            "  adding: output/final output/1909.08402v1.txt (stored 0%)\n",
            "  adding: output/final output/CrowdQM- Learning Aspect-Level User.txt (stored 0%)\n",
            "  adding: output/final output/An Improved Proportionate Normalized.txt (stored 0%)\n",
            "  adding: output/final output/P19-1466.txt (deflated 4%)\n",
            "  adding: output/final output/5067-Article Text-8130-1-10-20190709.txt (stored 0%)\n",
            "  adding: output/final output/NoALgo.txt (stored 0%)\n",
            "  adding: output/final output/2021.findings-emnlp.67.txt (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maxhRvoeYoub"
      },
      "source": [
        "annotations = {\n",
        "              'JARKA.txt' : ['JAPE','MultiKE','AttrE','MuGNN','BootEA','GCNs','KDCoE'],\n",
        "              'BiWalkLDA.txt':['LDAP', 'LRLSLDA', 'SIMCLDA','KATZHMDA','IRWRLDA','RWRlncD','MFLDA'],\n",
        "              'TemporalGAT.txt':['G-SAGE','GAT', 'Node2Vec', 'GraphSAGE', 'GCN-AE','GAT-AE','Know-Evolve', 'DynamicTriad','DynGEM', 'DySAT','DANE'],\n",
        "              'LoPAD.txt':['ALSO','COMBN','MBOM', 'iForest','LOF'],\n",
        "              'DELAFO.txt' : ['ResNet','ARMA','ARIMA','LSTM','GRU','SA','AA'],\n",
        "\n",
        "'A Benchmarking Study of Embedding based entity alignment for Knowledge Graphs (Springer).txt' : ['MTransE','IPTransE', 'JAPE', 'KDCoE', 'BootEA','GCNAlign','AttrE','IMUSE','SEA','RSN4EA','MultiKE','RDGCN','TransH', 'TransR', 'TransD', 'ProjE', 'ConvE', 'HolE', 'SimplE','RotatE','OpenKE','TuckER',\n",
        "'OpenEA','LogMap','NTAM','AC2Vec','Label2Vec','DistMult','Complex', 'KBGAN','DSKG','OTEA','NAEA','TransE','RGCN','AKE'],\n",
        "\n",
        "'A Proximity Weighted Evidential k.txt' : ['DTs','PEkNN','kNN', 'C4.5', 'NB','SMOTE', 'EKNN', 'WKNN', 'CCWKNN', 'kENN', 'GMDKNN','CCPDT', 'HDDT','iHDwDT'],\n",
        "\n",
        "\n",
        "'An Improved Proportionate Normalized.txt' : ['NLMS','PNLMS','IPNLMS','MPNLMS'],\n",
        "\n",
        "'AutoSUM - Automating Feature Extraction.txt' : ['LDA','LSTM-CRF','RELIN','SUMMARUM','FACES','ES-LDAext','ESA','DIVERSUM','CD','LinkSUM','MPSUM'],\n",
        "\n",
        "'Bottom-Up and Top-Down Graph Pooling.txt' : ['SAGPool','GCN','Graph-SAGE','SortPool','Set2Set','SAGPool','gPool','DiﬀPool'],\n",
        "\n",
        "\n",
        "'CACRNN- A Context-Aware.txt' : ['ARIMA','HA','DCRNN','STGCN','LSTM'],\t# Short form issue. Check what results you are getting for algo output\n",
        "\n",
        "'Chinese Sentence Semantic Matching.txt' : ['CNN','BiLSTM', 'BiMPM','DFF','DeepMatchtree','ARC-II','Match-Pyramid','Match-SRNN','MultiGranCNN', 'MV-LSTM', 'MPCM', 'DIIN','MIX','WMD',\n",
        "'CBOW'],\n",
        "\n",
        "'Correlation-aware Deep Generative Model for.txt' : ['OC-SVM','IF','DSEBM','DAGMM','AnoGAN','ALAD'],\n",
        "\n",
        "'CrowdQM- Learning Aspect-Level User.txt' : ['MBoA','CRH','TrustAnswer','CATD','CrowdQM-no-aspect'],\n",
        "\n",
        "'Deep Cost-Sensitive Kernel Machine for.txt' : ['BRNN-C','BRNN-D','Para2Vec','VDiscover','VulDeePecker','BRNN-SVM','Att-BGRU','Text CNN','MDSAE','OC-DeepSVDD'],\n",
        "\n",
        "'GAMMA-A Graph and Multi-view.txt' :['NeuACF','HERec','NeuMF','MF','BPR','FMG','KGAT','SemRec', 'MCRec', 'HeteRec'],\n",
        "\n",
        "'Joint Relational Dependency Learning.txt' : ['RNN','LSTM','BPR-MF','TranRec','GRU4Rec','FPMC','MARank'],\n",
        "\n",
        "'Mask-Guided Region Attention Network.txt' : ['PDC','AACN','PAN','PAR','DPFL','DaF','NFST','OIM','SVDNet','Spindle-Net','DLPAR','MSCAN'],\n",
        "\n",
        "\n",
        "\n",
        "'Multiple Demographic Attributes.txt' : ['POP','JNE','SNE','ETN','ETNA'],\t\t# Short form issue\n",
        "\n",
        "\n",
        "'Passenger demand forecasting with multi-task convolutional recurrent neural networks (accepted version).txt' : ['HA','ARIMA','SARIMA','OLSR','MLP','LSTM','XGBoost','DMVST-Net'],\n",
        "\n",
        "'Relation Embedding for Personalised.txt' : ['GeoSAGE', 'GraphSAGE','PMF','GeoMF','Rank-GeoFM','GeoSoCa','ST-LDA','TransRec','STA','GCN','DeepWalk','Node2Vec','CKN','MF','KGE'],\n",
        "\n",
        "'Robust Attribute and Structure.txt' : ['VGAE','Graph2Gauss','LINE','DeepWalk','node2vec','DVNE','TADW','GraphSAGE','Graph2Gauss','DANE','GLACE','G2G'],\n",
        "\n",
        "'SAFE.txt' : ['LIWC','VGG-19','att-RNN','TI-CNN','EANN'],\n",
        "\n",
        "'SGCN-A Graph Sparsifier.txt' : ['GCN','DUIF','RP','SS','DeepWalk','GraphSAGE'],\t\t# short form\n",
        "\n",
        "'SLGAT-Soft Labels Guided Graph.txt' : ['MLP','ManiReg','SemiEmb','LP','DeepWalk','ICA','Planetoid','ChebyNet','GCN','MoNet','GAT','SPAGAN','GraphHeat','GWNN','LINE'],\n",
        "\n",
        "'SoRecGAT- Leveraging Graph Attention.txt' : ['SAMN','DeepSoR','SBPR','TrustSVD','NeuMF','GMF','BPR','MF','RecGAT','SocialMF','SoReg','SR-GNN','GraphRec','PinSage','ATRank'],\n",
        "\n",
        "'SubRank-Subgraph Embeddings.txt' : ['DeepWalk','node2vec','LINE','VERSE','VerseAvg ','sub2vec','DeepCas','DeepHawkes','ParagraphVector'],\n",
        "\n",
        "\n",
        "'Towards Understanding Transfer Learning.txt': ['RPROJ3', 'PCA','TCA', 'GFK' , 'SA' , 'KMM' ,'MSDA', 'GFK','CORAL','ITL','GTL','LSDT','DAN' ,'RevGrad','ADDA' ,'DDC','DAN'],\n",
        "\n",
        "'CLINE.txt': ['BERT','RoBERTa','TextFooler','FreeLB','GPT'],\n",
        "\n",
        "'DOLORES Deep Contextualized Knowledge Graph Embeddings.txt' : ['RESCAL','TRANSE','DISTMULT','TRANSD','COMPLEX','CONVE','MANIFOLDE','HOLE','CONVKB','KBGAN','NODE2VEC','PTransE','PRA','RNN-Path','RNN-Path-entity'],\n",
        "\n",
        "'KBGAN.txt': ['RESCAL','TRANSE','DISTMULT','COMPLEX','TRANSH','TRANSR','TRANSD','MANIFOLDE','HOLE','CONVE','SEQGAN','IRGAN','WGAN','GOGAN','GANs',' Fast-TransX'],\n",
        "\n",
        "'new.txt' : ['XGBoost','TabNet','NODE','DNF-Net','1D-CNN','SVM','CatBoost'],\n",
        "\n",
        "'SCIBERT.txt' : ['BERT','ELMo','GPT','BIOBERT','CLINICALBERT']\n",
        "\n",
        "               }\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg7wAI88ZN-b"
      },
      "source": [
        "for k,v in annotations.items():\n",
        "  with open(\"annotations\"+\"/\"+k, 'w', encoding = 'utf-8') as f:\n",
        "    for ent in v:\n",
        "      f.write(ent+\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-CjASZbZ1AN",
        "outputId": "9d92963e-92cf-4f40-e7f5-a4261deed5c1"
      },
      "source": [
        "!zip -r annotations.zip annotations"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: annotations/ (stored 0%)\n",
            "  adding: annotations/CLINE.txt (stored 0%)\n",
            "  adding: annotations/Chinese Sentence Semantic Matching.txt (deflated 14%)\n",
            "  adding: annotations/BiWalkLDA.txt (deflated 15%)\n",
            "  adding: annotations/JARKA.txt (deflated 2%)\n",
            "  adding: annotations/TemporalGAT.txt (deflated 14%)\n",
            "  adding: annotations/SubRank-Subgraph Embeddings.txt (deflated 9%)\n",
            "  adding: annotations/DOLORES Deep Contextualized Knowledge Graph Embeddings.txt (deflated 16%)\n",
            "  adding: annotations/Bottom-Up and Top-Down Graph Pooling.txt (deflated 22%)\n",
            "  adding: annotations/Deep Cost-Sensitive Kernel Machine for.txt (deflated 7%)\n",
            "  adding: annotations/Robust Attribute and Structure.txt (deflated 21%)\n",
            "  adding: annotations/DELAFO.txt (deflated 6%)\n",
            "  adding: annotations/SCIBERT.txt (deflated 11%)\n",
            "  adding: annotations/A Benchmarking Study of Embedding based entity alignment for Knowledge Graphs (Springer).txt (deflated 29%)\n",
            "  adding: annotations/AutoSUM - Automating Feature Extraction.txt (deflated 7%)\n",
            "  adding: annotations/A Proximity Weighted Evidential k.txt (deflated 21%)\n",
            "  adding: annotations/Correlation-aware Deep Generative Model for.txt (stored 0%)\n",
            "  adding: annotations/Joint Relational Dependency Learning.txt (deflated 2%)\n",
            "  adding: annotations/Multiple Demographic Attributes.txt (deflated 10%)\n",
            "  adding: annotations/GAMMA-A Graph and Multi-view.txt (deflated 13%)\n",
            "  adding: annotations/SLGAT-Soft Labels Guided Graph.txt (deflated 11%)\n",
            "  adding: annotations/SGCN-A Graph Sparsifier.txt (stored 0%)\n",
            "  adding: annotations/KBGAN.txt (deflated 21%)\n",
            "  adding: annotations/CACRNN- A Context-Aware.txt (stored 0%)\n",
            "  adding: annotations/An Improved Proportionate Normalized.txt (deflated 36%)\n",
            "  adding: annotations/SAFE.txt (deflated 3%)\n",
            "  adding: annotations/CrowdQM- Learning Aspect-Level User.txt (stored 0%)\n",
            "  adding: annotations/LoPAD.txt (stored 0%)\n",
            "  adding: annotations/Relation Embedding for Personalised.txt (deflated 10%)\n",
            "  adding: annotations/Towards Understanding Transfer Learning.txt (deflated 13%)\n",
            "  adding: annotations/Mask-Guided Region Attention Network.txt (deflated 9%)\n",
            "  adding: annotations/new.txt (deflated 10%)\n",
            "  adding: annotations/SoRecGAT- Leveraging Graph Attention.txt (deflated 11%)\n",
            "  adding: annotations/Passenger demand forecasting with multi-task convolutional recurrent neural networks (accepted version).txt (deflated 6%)\n"
          ]
        }
      ]
    }
  ]
}
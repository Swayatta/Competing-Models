Deep Cost-Sensitive Kernel Machine for
Binary Software Vulnerability Detection

Tuan Nguyen1(B), Trung Le1, Khanh Nguyen2, Olivier de Vel3,

Paul Montague3, John Grundy1, and Dinh Phung1

1 Monash University, Melbourne, Australia

{tuan.nguyen,trunglm,john.grundy,dinh.phung}@monash.edu

2 AI Research Lab, Trusting Social, Melbourne, Australia

khanh.nguyen@trustingsocial.com

3 Defence Science and Technology Group, Canberra, Australia

{olivier.devel,paul.montague}@dst.defence.gov.au

Abstract. Owing to the sharp rise in the severity of the threats imposed
by software vulnerabilities, software vulnerability detection has become
an important concern in the software industry, such as the embedded
systems industry, and in the ﬁeld of computer security. Software vulner-
ability detection can be carried out at the source code or binary level.
However, the latter is more impactful and practical since when using
commercial software, we usually only possess binary software. In this
paper, we leverage deep learning and kernel methods to propose the
Deep Cost-sensitive Kernel Machine, a method that inherits the advan-
tages of deep learning methods in eﬃciently tackling structural data and
kernel methods in learning the characteristic of vulnerable binary exam-
ples with high generalization capacity. We conduct experiments on two
real-world binary datasets. The experimental results have shown a con-
vincing outperformance of our proposed method over the baselines.

1 Introduction

Software vulnerabilities are speciﬁc ﬂaws or oversights in a piece of software that
can potentially allow attackers exploit the code to perform malicious acts includ-
ing exposing or altering sensitive information, disrupting or destroying a system,
or taking control of a computer system or program. Because of the ubiquity of
computer software and the growth and the diversity in its development process,
a great deal of computer software potentially possesses software vulnerabilities.
This makes the problem of software vulnerability detection an important concern
in the software industry and in the ﬁeld of computer security.

Software vulnerability detection consists of source code and binary code vulner-
ability detection. Due to a large loss of the syntactic and semantic information pro-
vided by high-level programming languages during the compilation process, binary
code vulnerability detection is signiﬁcantly more diﬃcult than source code vulner-
ability detection. In addition, in practice, binary vulnerability detection is more
applicable and impactful than source code vulnerability detection. The reason is
that when using a commercial application, we only possess its binary and usually do
c(cid:2) Springer Nature Switzerland AG 2020
H. W. Lauw et al. (Eds.): PAKDD 2020, LNAI 12085, pp. 164–177, 2020.
https://doi.org/10.1007/978-3-030-47436-2_13

Deep Cost-Sensitive Kernel Machine

165

not possess its source code. The ability to detect the presence or absence of vulner-
abilities in binary code, without getting access to source code, is therefore of major
importance in the context of computer security. Some work has been proposed to
detect vulnerabilities at the binary code level when source code is not available,
notably work based on fuzzing, symbolic execution [1], or techniques using hand-
crafted features extracted from dynamic analysis [4]. Recently, the work of [10]
has pioneered learning automatic features for binary software vulnerability detec-
tion. In particular, this work was based on a Variational Auto-encoder [7] to work
out representations of binary software so that representations of vulnerable and
non-vulnerable binaries are encouraged to be maximally diﬀerent for vulnerabil-
ity detection purposes, while still preserving crucial information inherent in the
original binaries.

By nature, datasets for binary software vulnerability detection are typically
imbalanced in the sense that the number of vulnerabilities is very small com-
pared to the volume of non-vulnerable binary software. Another important trait
of binary software vulnerability detection is that misclassifying vulnerable code as
non-vulnerable is much more severe than many other misclassiﬁcation decisions. In
the literature, kernel methods in conjunction with the max-margin principle have
shown their advantages in tackling imbalanced datasets in the context of anomaly
and novelty detection [13,18,21]. The underlying idea is to employ the max-margin
principle to learn the domain of normality, which is decomposed into a set of con-
tours enclosing normal data that helps distinguish normality against abnormal-
ity. However, kernel methods are not able to eﬃciently handle sequential machine
instructions in binary software. In contrast, deep recursive networks (e.g., recur-
rent neural networks or bidirectional recurrent neural networks) are very eﬃcient
and eﬀective in tackling and exploiting temporal information in sequential data
like sequential machine instructions in binary software.

To cope with the diﬀerence in the severity level of the kinds of misclassiﬁca-
tion, cost-sensitive loss has been leveraged with kernel methods in some previ-
ous works, notably [2,5,12]. However, these works either used non-decomposable
losses or were solved in the dual form, which makes them less applicable to lever-
age with deep learning methods in which stochastic gradient descent method is
employed to solve the corresponding optimization problem.

To smoothly enable the incorporation of kernel methods, cost-sensitive loss,
and deep learning in the context of binary code vulnerability detection, we pro-
pose a novel Cost-sensitive Kernel Machine (CKM) which is developed based on
the max-margin principle to ﬁnd two optimal parallel hyperplanes and employs
cost sensitive loss to ﬁnd the best decision hyperplane. In particular, our CKM
ﬁrst aims to learn two parallel hyperplanes that can separate vulnerability and
non-vulnerability, while the margin which is deﬁned as the distance between
the two parallel hyperplanes is maximized. The optimal decision hyperplane of
CKM is sought in the strip formed by the two parallel hyperplanes. To take
into account the diﬀerence in importance level of two kinds of misclassiﬁcation,
we employ a cost-sensitive loss, where the misclassiﬁcation of vulnerability as
non-vulnerability is assigned a higher cost.

166

T. Nguyen et al.

Fig. 1. An overview of the data processing and embedding process.

We conduct experiments over two datasets, the NDSS18 binary dataset whose
source code was collected and compiled to binaries in [10,15] and binaries com-
piled from 6 open-source projects, which is a new dataset created by us. We
strengthen and extend the tool developed in [10] to allow it to be able to handle
more errors for compiling the source code in the six open-source projects into
binaries. Our experimental results over these two binary datasets show that our
proposed DCKM outperforms the baselines by a wide margin.

The major contributions of our work are as follows:

– We upgrade the tool developed in [10] to create a new real-world binary

dataset.

– We propose a novel Cost-sensitive Kernel Machine that takes into account the
diﬀerence in incurred costs of diﬀerent kinds of misclassiﬁcation and imbal-
anced data nature in binary software vulnerability detection. This CKM can
be plugged neatly into a deep learning model and be trained using back-
propagation.

– We leverage deep learning, kernel methods, and a cost-sensitive based app-
roach to build a novel Deep Cost-sensitive Kernel Machine that outperforms
state-of-the-art baselines on our experimental datasets by a wide margin.

2 Our Approach: Deep Cost-Sensitive Kernel Machine

By incorporating deep learning and kernel methods, we propose a Deep Cost-
sensitive Kernel Machine (DCKM) for binary software vulnerability detection. In
particular, we use a bidirectional recurrent neural network (BRNN) to summarize
a sequence of machine instructions in binary software into a representation vec-
tor. This vector is then mapped into a Fourier random feature space via a ﬁnite-
dimensional random feature map [9,11,14,17,19]. Our proposed Cost-sensitive
Kernel Machine (CKM) is invoked in the random feature space to detect vulner-
able binary software. Note that the Fourier random feature map which is used in
conjunction with our CKM and BRNN enables our DCKM to be trained nicely via
back-propagation.

2.1 Data Processing and Embedding

Deep Cost-Sensitive Kernel Machine

167

Figure 1 presents an overview of the code data processing steps required to obtain
the core parts of machine instructions from source code. From the source code
repository, we identify the code functions and then ﬁx any syntax errors using
our automatic tool. The tool also invokes the gcc compiler to compile com-
pilable functions into binaries. Subsequently, utilizing the objdump1 tool, we
disassemble the binaries into assembly code. Each function corresponds to an
assembly code ﬁle. We then process the assembly code ﬁles to obtain a collec-
tion of machine instructions and eventually use the Capstone 2 framework to
extract their core parts. Each core part in a machine instruction consists of two
components: the opcode and the operands, called the instruction information (a
sequence of bytes in hexadecimal format, i.e., memory location, registers, etc.).
The opcode indicates the type of operation, whilst the operands contain the
necessary information for the corresponding operation. Since both opcode and
operands are important, we embed both the opcode and instruction information
into vectors and then concatenate them.

To embed the opcode, we undertake
some preliminary analysis and ﬁnd that
there were a few hundred opcodes in
our dataset. We then build a vocabulary
of the opcodes, and after that embed
them using one-hot vectors to obtain
the opcode embedding eop.

is

follows. We consider

Fig. 2. Machine instruction embedding
process with examples. The opcode
embedding eop
concatenated with
instruction information embedding eii to
obtain the output embedding e, a 2d-
dimensional vector.

To embed the instruction informa-
tion, we ﬁrst compute the frequency
vector as
the
operands as a sequence of hexadec-
imal bytes (i.e., 00, 01 to F F ) and
count the frequencies of the hexadec-
imal bytes to obtain a frequency vec-
tor with 256 dimensions. The frequency
vector is then multiplied by the embed-
ding matrix to obtain the instruction
information embedding eii.
More speciﬁcally, the output embedding is e = eop (cid:2) eii where eop =
one-hot(op) × W op and eii = freq (ii) × W ii with the opcode op, the instruction
information ii, one-hot vector one-hot(op), frequency vector freq (ii), and the
embedding matrices W op ∈ R
V ×d and W ii ∈ R256×d, where V is the vocabulary
size of the opcodes and d is the embedding dimension. The process of embedding
machine instructions is presented in Fig. 2.

1 https://www.gnu.org/software/binutils/.
2 https://www.capstone-engine.org.

168

T. Nguyen et al.

2.2 General Framework of Deep Cost-Sensitive Kernel Machine

(cid:3)

−→
h L

(cid:2)←−
h L,

for the binary x, where

We now present the general framework for our proposed Deep Cost-sensitive
Kernel Machine. As shown in Fig. 3, given a binary x, we ﬁrst embed its machine
instructions into vectors (see Sect. 2.1); the resulting vectors are then fed to a
Bidirectional RNN with the sequence lenght of L to work out the representation
−→
h L are the left and right
h = concat
L-th hidden states (the left and right last hidden states) of the Bidirectional
RNN, respectively. Finally, the vector representation h is mapped to a random
feature space via a random feature map ˜Φ (·) [19] where we recruit a cost-sensitive
kernel machine (see Sect. 2.3) to classify vulnerable and non-vulnerable binary
software. Note that the formulation for ˜Φ is as follows:
(cid:6)(cid:7)D

←−
h L and

(cid:4)

(cid:5)

˜Φ (h) =

1√
D

cos

(cid:5)

(cid:6)
i h

ωT

, 1√
D

sin

ωT

i h

∈ R2D

i=1

(1)

where ω1, . . . , ωD are the Fourier random elements as in [19] and the dimension
of random feature space is hence 2D.

Fig. 3. General framework of Deep Cost-sensitive Kernel Machine.

We note that the use of a random feature map in conjunction with cost-
sensitive kernel machine and bi-directional RNN allows us to easily do back-
propagation when training our Deep Cost-sensitive Kernel Machine. In addition,
let us denote the training set of binaries and their labels by D = {(xi, yi)}N
where xi is a binary including many machine instructions and yi ∈ {−1; 1}
i=1
where the label −1 stands for vulnerable binary and the label 1 stands for non-
vulnerable binary. Assume that after feeding the binaries x1, . . . , xN into the cor-
responding BRNN as described above, we obtain the representations h1, . . . , hN .
We then map these representations to the random feature space via the random
feature map ˜Φ (·) as deﬁned in Eq. (1). We ﬁnally construct a cost-sensitive ker-
nel machine (see Sect. 2.3) in the random feature space to help us distinguish
vulnerability against non-vulnerability.

Deep Cost-Sensitive Kernel Machine

169

2.3 Cost-Sensitive Kernel Machine

General Idea of Cost-Sensitive Kernel Machine. We ﬁrst ﬁnd two parallel
hyperplanes H−1 and H1 in such a way that H−1 separates the non-vulnerable
and vulnerable classes, H1 separates the vulnerable and non-vulnerable classes,
and the margin, which is the distance between the two parallel hyperplanes H−1
and H1, is maximized. We then ﬁnd the optimal decision hyperplane Hd by
searching in the strip formed by H−1 and H1 (see Fig. 4).

Formulations of the Hard and Soft Models. Let us denote the equations
of H−1 and H1 by H−1 : wT ˜Φ (h) − b−1 = 0 and H1 : wT ˜Φ (h) − b1 = 0 where
b1 > b−1. The margin is hence formulated as d (H−1,H1) =
(cid:3)w(cid:3) = b1−b−1
|b1−b−1|
(cid:3)w(cid:3) .
We arrive at the optimization problem:

(cid:8)

(cid:9)

b1 − b−1
(cid:2)w(cid:2)
(cid:2)
wT ˜Φ (hi) − b−1
(cid:2)
(cid:3)
wT ˜Φ (hi) − b1

max
w,b−1,b1

s.t. :yi

yi

(cid:3)

≥ 0, ∀i = 1, . . . , N
≥ 0, ∀i = 1, . . . , N

It is worth noting that the margin d (H−1,H1) is invariant if we scale (w, b−1, b1)
by a factor k > 0 as (kw, kb−1, kb1). Therefore, we can safely assume that
b1 − b−1 = 1, and hence the following optimization problem:

(cid:8)

(cid:9)

min
w,a

s.t. :yi

yi

(cid:2)w(cid:2)2
1
(cid:2)
(cid:3)
2
≥ 0, ∀i = 1, . . . , N
wT ˜Φ (hi) − a
(cid:2)
(cid:3)
wT ˜Φ (hi) − 1 − a

≥ 0, ∀i = 1, . . . , N

where b−1 = a and b1 = 1 + a.

Invoking slack variables, we obtain the soft model:

(cid:10)

(cid:12)
N(cid:11)
(cid:2)w(cid:2)2 +
1
λ
(ξi + ψi)
2
N
(cid:2)
(cid:3)
wT ˜Φ (hi) − a
≥ −ξi, ∀i = 1, . . . , N
(cid:2)
(cid:3)
wT ˜Φ (hi) − 1 − a

i=1

≥ −ψi, ∀i = 1, . . . , N

min
w,a

s.t. :yi

yi

i=1 are non-negative slack variables and λ > 0 is the regu-

The primal form of the soft model optimization problem is hence of the

where [ξi]N
i=1 and [ψi]N
larization parameter.

following form:

170

T. Nguyen et al.

(cid:10)

min
w,a

λ
2

(cid:2)w(cid:2)2 +

1
N

N(cid:11)

(cid:2)

max

i=1

max

(cid:13)
0,−yi

(cid:2)

(cid:13)
0,−yi
(cid:2)

wT ˜Φ (hi) − a

(cid:3)(cid:14)
+
(cid:3)(cid:14)(cid:3)(cid:12)

wT ˜Φ (hi) − 1 − a

(2)

Finding the Optimal Decision Hyperplane. After solving the optimization
−1 = a∗
problem in Eq. (2), we obtain the optimal solution
1 = 1 + a∗ for the two parallel hyperplanes. Let us denote the strip S
and b∗
formed by the two parallel hyperplanes and the set of training examples I in
this strip as:

where b∗

w∗, b∗
−1

, b∗

1

(cid:5)

(cid:6)

∗

(cid:13)
≤ v ≤ (w
v | (w
(cid:14)
(cid:13)
i | ˜Φ (hi) ∈ S, 1 ≤ i ≤ N

)T u − b∗

1

S =
I =

∗

)T u − b∗

−1 for some u

(cid:14)

where u, v lie in the random feature space R2D.

Fig. 4. Cost-sensitive kernel machine in the ran-
dom feature space. We ﬁrst ﬁnd two optimal
parallel hyperplanes H1 and H−1 with maximal
margin and then search for the optimal decision
hyperplane in the strip S formed by H1 and H−1
to balance between precision and recall for min-
imizing the cost-sensitive loss and obtaining a
good F1 score.

As shown in Fig. 4, when slid-
ing a hyperplane from H1 to
H−1, the recall is increased, but
the precision is decreased.
In
contrast, when sliding a hyper-
plane from H−1 to H1, the pre-
cision is increased, but the recall
is decreased. We hence desire
to ﬁnd out the optimal decision
hyperplane to balance between
precision and recall for minimiz-
ing the cost-sensitive loss and
obtaining good F1 scores. We
also conduct
intensive experi-
ments on real datasets to empir-
ically demonstrate this intuition
in Sect. 3.4.
Inspired by this observation, we seek the optimal decision hyperplane Hd by
minimizing the cost-sensitive loss for the training examples inside the strip S,
where we treat the two kinds of misclassiﬁcation unequally. In particular, the
cost of misclassifying a non-vulnerability as a vulnerability is 1, while misclas-
sifying a vulnerability as a non-vulnerability is θ. The value of θ, the relative
cost between two kinds of misclassiﬁcation, is set depending on speciﬁc appli-
cations. In this application, we set θ = #non-vul : #vul >> 1, which makes
sense because, in binary software vulnerability detection, the cost suﬀered by
classifying vulnerable binary code as non-vulnerable is, in general, much more
severe than the converse.

Deep Cost-Sensitive Kernel Machine

171

Let |I| = M where |·| speciﬁes the cardinality of a set and arrange the
elements of I according to their distances to H−1 as I = {i1, i2, . . . , iM} where
(w∗)T ˜Φ (hi1) ≤ (w∗)T ˜Φ (hi2) ≤ ··· ≤ (w∗)T ˜Φ (hiM ). We now deﬁne the cost-
sensitive loss for a given decision hyperplane: (w∗)T ˜Φ (h) − bm
d = 0 in which we
denote

,

−1 + (w∗)T ˜Φ (hi1)
b∗
(w∗)T ˜Φ

(cid:5)
2
him−1

(cid:6)

+ (w∗)T ˜Φ (him)
2
(w∗)T ˜Φ (hiM ) + b∗

1

d =
b1

bm
d =

bM +1
d

=

2

, 2 ≤ m ≤ M,

and the optimal decision hyperplane (w∗)T ˜Φ (h) − b∗
(cid:11)

(cid:11)

d = 0 as:

∗, bm

d ) = θ

l (w

I

d <0 +
(w∗)T ˜Φ(h ik)−bm
yik =−1
d ) and b∗
∗, bm

l (w

= argmin
1≤m≤M+1

yik =1
m∗

d = bm∗

d

I

(w∗)T ˜Φ(h ik)−bm

d >0

where the indicator function IS returns 1 if S is true and 0 if otherwise.
It is worth noting if #non-vul ≈ #vul (i.e., θ ≈ 1), we obtain a Support
Vector Machine [3] and if #non-vul >> #vul (i.e., θ ≈ 0), we obtain a One-
class Support Vector Machine [21]. We present Algorithm 1 to eﬃciently ﬁnd
the optimal decision hyperplane. The general idea is to sequentially process the
M +1 possible hyperplanes: (w∗)T ˜Φ (h)−bm
d = 0, ∀i = 1, . . . , M +1 and compute
the cost-sensitive loss cumulatively. The computational cost of this algorithm
includes: i) the cost to determine S, which is O (2DN), ii) the cost to sort the
elements in S according to their distances to H−1, which is O (M log M), and
iii) the cost to process the possible hyperplanes, which is O (M + 1).

d

1

∗

∗

)

∗, b∗

−1, b∗

T ˜Φ (hi1 ) ≤ (w

Algorithm 1. Pseudo-code for seeking the optimal decision hyperplane.
Input: D = {(x1, y1) , . . . , (xN , yN )}, w
Output: m∗, b∗
1: Determine S and I
2: Sort the elements in I as (w
3: loss = |{i ∈ I | yi = −1}| ;
4: m∗
5: repeat
6:
7:
8:
9:
10:
11: until t > M + 1

= 1; b∗
(yit == 1)?loss = loss + θ : loss = loss − 1;
if loss < minLoss then
minLoss = loss; m∗

T ˜Φ (hi2 ) ≤ ··· ≤ (w
)

d; minLoss = loss; t = 1;

end if
t = t + 1;

d = b1

= t;

∗

T ˜Φ (hiM )
)

//all in S are classiﬁed as +

172

T. Nguyen et al.

3 Experiments

3.1 Experimental Datasets

Creating labeled binary datasets for binary code vulnerability detection is one
of the main contributions of our work. We ﬁrst collected the source code from
two datasets on GitHub: NDSS183 and six open-source projects4 collected in
[16] and then processed to create 2 labeled binary datasets.

NDSS18

#Non-vul #Vul #Binaries

Table 1. The statistics of the two binary
datasets.

The NDSS18 binary dataset was
created in previous work [10] – the
functions were extracted from the
original source code and then com-
piled successfully to obtain 8, 991
binaries using an automated tool.
However,
the source code in the
NDSS18 dataset involves the code
weaknesses CWE119 and CWE399,
resulting in short source code chunks
used to demonstrate the vulnerable
examples, hence not perfectly reﬂecting real-world source code, while the source
code ﬁles collected from the six open-source projects, namely FFmpeg, LibTIFF,
LibPNG, VLC, Pidgin and Asterisk are all real-world examples. The statistics
of our binary datasets are given in Table 1.

Windows 8, 999
6, 955
Linux
Whole
15, 954
6 open-source Windows 26, 621
25, 660
52, 281

8, 978 17, 977
7, 349 14, 304
16, 327 32, 281
26, 949
328
25, 950
290
618
52, 899

Linux
Whole

3.2 Baselines

We compared our proposed DCKM with various baselines:

– BRNN-C, BRNN-D: A vanilla Bidirectional RNN with a linear classiﬁer

and two dense layers on the top.

– Para2Vec: The paragraph-to-vector distributional similarity model proposed
in [8] which allows us to embed paragraphs into a vector space which are
further classiﬁed using a neural network.

– VDiscover: An approach proposed in [4] that utilizes lightweight static fea-
tures to “approximate” a code structure to seek similarities between program
slices.

– VulDeePecker: An approach proposed in [15] for source code vulnerability

detection.

– BRNN-SVM: The Support Vector Machine using linear kernel, but lever-

aging our proposed feature extraction method.

– Att-BGRU: An approach developed by [22] for sequence classiﬁcation using

– Text CNN: An approach proposed in [6] using a Convolutional Neural Net-

the attention mechanism.

work (CNN) to classify text.

3 https://github.com/CGCL-codes/VulDeePecker.
4 https://github.com/DanielLin1986/TransferRepresentationLearning.

– MDSAE: A method called Maximal Divergence Sequential Auto-Encoder in

Deep Cost-Sensitive Kernel Machine

173

[10] for binary software vulnerability detection.

– OC-DeepSVDD: The One-class Deep Support Vector Data Description

method proposed in [20].

The implementation of our model and the binary datasets for reproducing
the experimental results can be found online at https://github.com/tuanrpt/
DCKM.

Table 2. The experimental results (%) except for the column CS of the proposed
method compared with the baselines on the NDSS18 binary dataset. Pre, Rec, and CS
are shorthand for the performance measures precision, recall, and cost-sensitive loss,
respectively.

Datasets
Methods

Windows

Linux

Whole

Pre F1 Rec AUC CS Pre F1 Rec AUC CS Pre F1 Rec AUC CS

17.5 24.1 38.9 67.6 0.98 36.4 44.4 57.1 77.6 0.83 28.6 26.7 25.0 61.9 0.96
Para2Vec
58.8 57.1 55.6 77.4 0.90 52.9 58.1 64.3 81.6 0.68 48.4 47.6 46.9 72.9 0.93
Vdiscover
80.0 84.2 88.9 94.2 0.89 76.9 74.1 71.4 85.5 0.65 84.6 75.9 68.7 84.2 0.87
BRNN-C
77.8 77.8 77.8 88.7 0.92 92.3 88.9 85.7 92.8 0.68 85.2 78.0 71.9 85.8 0.81
BRNN-D
VulDeePecker
70.0 73.7 77.8 88.6 0.98 80.0 82.8 85.7 92.6 0.70 85.2 78.0 71.9 85.8 0.84
BRNN-SVM 79.0 81.1 83.3 91.4 0.98 92.3 88.9 85.7 92.8 0.68 85.7 80.0 75.0 87.4 0.84
92.3 77.4 66.7 83.3 0.97 92.3 88.9 85.7 92.8 0.68 86.5 79.3 71.9 85.8 0.82
Att-BGRU
92.3 77.4 66.7 83.3 0.99 91.7 84.6 78.6 89.2 0.74 84.6 75.9 68.7 84.2 0.85
Text CNN
77.7 86.4 97.2 84.4 0.11 80.6 88.3 97.7 86.8 0.05 78.4 87.1 98.1 85.2 0.72
MDSAE
OC-DeepSVDD 91.7 73.3 61.1 80.5 0.19 100 83.3 71.4 85.7 0.14 85.5 78.1 71.9 83.1 0.84
84.2 86.588.9 94.3 0.06 92.9 92.9 92.9 96.4 0.03 87.1 85.7 84.4 92.1 0.58
DCKM

Table 3. The experimental results (%) except for the column CS of the proposed
method compared with the baselines on the binary dataset from the six open-source
projects. Pre, Rec, and CS are shorthand for the performance measures precision, recall,
and cost-sensitive loss, respectively.

Datasets

Methods

Para2Vec

Windows

Linux

Whole

Pre F1 Rec AUC CS Pre F1 Rec AUC CS Pre F1 Rec AUC CS

28.9 31.0 33.3 66.2 0.96 19.2 24.0 32.1 65.3 0.98 28.1 26.9 25.8 62.5 0.97

Vdiscover

23.3 22.2 21.2 60.2 0.98 42.1 34.0 28.6 64.1 0.92 18.0 13.9 11.3 55.3 0.98

BRNN-C

42.9 25.5 18.2 59.0 0.97 53.9 34.2 25.0 62.4 0.93 43.2 32.3 25.8 62.7 0.95

BRNN-D

30.8 27.1 24.2 61.8 0.96 46.2 29.3 21.4 60.6 0.96 36.7 25.3 19.4 59.5 0.98

VulDeePecker 31.6 23.1 18.2 58.9 0.97 53.9 34.2 25.0 62.4 0.94 65.5 41.8 30.7 65.2 0.93

BRNN-SVM 73.9 60.7 51.5 75.6 0.98 87.5 63.6 50.0 75.0 0.99 65.6 65.0 64.5 82.1 0.91
70.8 59.7 51.5 75.6 0.92 100 56.4 39.3 69.7 0.93 85.1 73.4 64.5 82.2 0.91
100 70.6 54.6 77.3 0.90 81.8 72.0 64.3 82.0 0.89 100 74.8 59.7 79.8 0.91

Att-BGRU

Text CNN

MDSAE
88.2 60.0 45.5 72.7 0.91 60.0 41.9 32.1 66.0 0.93 82.4 74.3 67.7 83.8 0.90
OC-DeepSVDD 100 77.8 63.6 81.8 0.83 88.9 69.6 57.1 78.5 0.90 100 70.8 54.8 77.4 0.89
79.480.681.8 90.8 0.7890.075.064.3 82.1 0.8590.390.390.3 95.1 0.56

DCKM

174

T. Nguyen et al.

3.3 Parameter Setting

For our datasets, we split the data into 80% for training, 10% for validation, and
the remaining 10% for testing. For the NDSS18 binary dataset, since it is used
for the purpose of demonstrating the presence of vulnerabilities, each vulnerable
source code is associated with its ﬁxed version, hence this dataset is quite balanced.
To mimic a real-world scenario, we made this dataset imbalanced by randomly
removing vulnerable source code to keep the ratio #vul : #non-vul = 1 : 50. For
the dataset from six open-source projects, we did not modify the datasets since
they are real-world datasets.

Fig. 5. Predictive scores and the number of data examples in the S strip after 100
epochs.

(cid:13)
−γ (cid:2)x − x(cid:5)(cid:2)2

We employed a dynamic BRNN to tackle the variation in the number of
machine instructions of the functions. For the BRNN baselines and our models,
the size of the hidden unit was set to 128 for the six open-source projects’s binary
dataset and 256 for the NDSS18 dataset. For our model, we used Fourier random
(cid:14)
kernel with the number of random features 2D = 512 to approximate the RBF
kernel, deﬁned as K (x, x(cid:5)) = exp
, wherein the width of the
kernel γ was searched in {2−15, 2−3} for the dataset from 6 open-source projects
and NDSS18 dataset, respectively. The regularization parameter λ was 0.01. We
set the relative cost θ = #non-vul : #vul. We used the Adam optimizer with
an initial learning rate equal to 0.0005. The minibatch size was set to 64 and
results became promising after 100 training epochs. We implemented our pro-
posed method in Python using Tensorﬂow, an open-source software library for
Machine Intelligence developed by the Google Brain Team. We ran our experi-
ments on a computer with an Intel Xeon Processor E5-1660 which had 8 cores
at 3.0 GHz and 128 GB of RAM. For each dataset and method, we ran the
experiment ﬁve times and reported the average predictive performance.

3.4 Experimental Results

Experimental Results on the Binary Datasets. We conducted a variety of
experiments on our two binary datasets. We split each dataset into three parts:
the subset of Windows binaries, the subset of Linux binaries, and the whole set
of binaries to compare our methods with the baselines.

Deep Cost-Sensitive Kernel Machine

175

In the ﬁeld of computer security, besides the AUC and F1 score which takes
into account both precision and recall, the cost-sensitive loss, wherein we con-
sider the fact that the misclassiﬁcation of a vulnerability as a non-vulnerability is
more severe than the converse, is also very important. The experimental results
on the two datasets are shown in Table 2 and 3. It can be seen that our pro-
posed method outperforms the baselines in all performance measures of interest
including the cost-sensitive loss, F1 score, and AUC. Especially, our method sig-
niﬁcantly surpasses the baselines on the AUC score, one of the most important
measures of success for anomaly detection. In addition, although our proposed
DCKM aims to directly minimize the cost-sensitive loss, it can balance between
precision and recall to maintain very good F1 and AUC scores. In what follows,
we further explain this claim.

Fig. 6. The variation of predictive scores when sliding the hyperplane in the strip
formed by H−1 and H1 on the NDSS18 (left) and the dataset from six open-source
projects (right). The red line illustrates the tendency of the cost-sensitive loss, while
the purple star and the red star represent the optimal F1 and the optimal cost-sensitive
loss values, respectively. (Color ﬁgure online)

Inspection of Model Behaviors
Discovering the trend of scores and number of data points in the strip during
the training process Fig. 5 shows the predictive scores and the number of data
examples in the parallel strip on training and valid sets for the binary dataset
from six open-source projects across the training process. It can be observed
that the model gradually improves during the training process with an increase
in the predictive scores, and a reduction in the amount of data in the strip from
around 1,700 to 50.
The tendency of predictive scores when sliding the decision hyperplane in the
strip formed by H−1 and H1 By minimizing the cost-sensitive loss, we aim to ﬁnd
the optimal hyperplane which balances precision and recall, while at the same
time maintaining good F1 and AUC scores. Figure 6 shows the tendency of scores
and cost-sensitive loss when sliding the decision hyperplane in the strip formed
by H−1 and H1. We especially focus on four milestone hyperplanes, namely H−1,
H1, the hyperplane that leads to the optimal F1 score, and the hyperplane that
leads to the optimal cost-sensitive loss (i.e., our optimal decision hyperplane). As
shown in Fig. 6, our optimal decision hyperplane marked with the red stars can

176

T. Nguyen et al.

achieve the minimal cost-sensitive loss, while maintaining comparable F1 and
AUC scores compared with the optimal-F1 hyperplane marked with the purple
stars.

4 Conclusion

Binary software vulnerability detection has emerged as an important and crucial
problem in the software industry, such as the embedded systems industry, and
in the ﬁeld of computer security. In this paper, we have leveraged deep learn-
ing and kernel methods to propose the Deep Cost-sensitive Kernel Machine for
tackling binary software vulnerability detection. Our proposed method inherits
the advantages of deep learning methods in eﬃciently tackling structural data
and kernel methods in learning the characteristic of vulnerable binary exam-
ples with high generalization capacity. We conducted experiments on two binary
datasets. The experimental results have shown a convincing outperformance of
our proposed method compared to the state-of-the-art baselines.

Acknowledgement. This research was supported under the Defence Science and
Technology Group‘s Next Generation Technologies Program.


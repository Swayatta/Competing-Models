ResearchArticleAnImprovedProportionateNormalizedLeast-Mean-SquareAlgorithmforBroadbandMultipathChannelEstimationYingsongLiandMasanoriHamamuraGraduateSchoolofEngineering,KochiUniversityofTechnology,Kami-shi782-8502,JapanCorrespondenceshouldbeaddressedtoYingsongLi;liyingsong@ieee.orgReceived27December2013;Accepted19February2014;Published20March2014AcademicEditors:H.R.Karimi,X.Yang,Z.Yu,andW.ZhangCopyright©2014Y.LiandM.Hamamura.ThisisanopenaccessarticledistributedundertheCreativeCommonsAttributionLicense,whichpermitsunrestricteduse,distribution,andreproductioninanymedium,providedtheoriginalworkisproperlycited.Tomakeuseofthesparsitypropertyofbroadbandmultipathwirelesscommunicationchannels,wemathematicallyproposean𝑙𝑝-norm-constrainedproportionatenormalizedleast-mean-square(LP-PNLMS)sparsechannelestimationalgorithm.Ageneral𝑙𝑝-normisweightedbythegainmatrixandisincorporatedintothecostfunctionoftheproportionatenormalizedleast-mean-square(PNLMS)algorithm.Thisintegrationisequivalenttoaddingazeroattractortotheiterations,bywhichtheconvergencespeedandsteady-stateperformanceoftheinactivetapsaresignificantlyimproved.OursimulationresultsdemonstratethattheproposedalgorithmcaneffectivelyimprovetheestimationperformanceofthePNLMS-basedalgorithmforsparsechannelestimationapplications.1.IntroductionBroadbandsignaltransmissionisbecomingacommonlyusedhigh-data-ratetechniquefornext-generationwirelesscommunicationsystems,suchas3GPPlong-termevolu-tion(LTE)andworldwideinteroperabilityformicrowaveaccess(WiMAX)[1].Thetransmissionperformanceofcoher-entdetectionforsuchbroadbandcommunicationsystemsstronglydependsonthequalityofchannelestimation[2–5].Fortunately,broadbandmultipathchannelscanbeaccuratelyestimatedusingadaptivefiltertechniques[6–10]suchasthenormalizedleast-mean-square(NLMS)algorithm,whichhaslowcomplexityandcanbeeasilyimplementedatthereceiver.Ontheotherhand,channelmeasurementshaveshownthatbroadbandwirelessmultipathchannelscanoftenbedescribedbyonlyasmallnumberofpropagationpathswithlongdelays[4,11,12].Thus,abroadbandmultipathchannelcanberegardedasasparsechannelwithonlyafewactivedominanttaps,whiletheotherinactivetapsarezeroorclosetozero.Thisinherentsparsityofthechannelimpulseresponse(CIR)canbeexploitedtoimprovethequalityofchannelestimation.However,suchclassicalNLMSalgorithmswithauniformstepsizeacrossallfiltercoefficientshaveslowconvergencewhenestimatingsparseimpulseresponsesignalssuchasthoseinbroadbandsparsewirelessmultipathchannels[11].Consequently,correspond-ingalgorithmshaverecentlyreceivedsignificantattentioninthecontextofcompressedsensing(CS)[5,12–14]andwerealreadyconsideredforchannelestimationpriortotheCSera[5,12].However,theseCSchannelestimationalgorithmsaresensitivetothenoiseinwirelessmultipathchannels.InspiredbytheCStheory[12–14],severalzero-attracting(ZA)algorithmshavebeenproposedandinvestigatedbycombiningtheCStheoryandthestandardleast-mean-square(LMS)algorithmforechocancellationandsystemidentification,whichareknownasthezero-attractingLMS(ZA-LMS)andreweightedZA-LMS(RZA-LMS)algorithms,respectively[15].Recently,thistechniquehasbeenexpandedtotheNLMSalgorithmandotheradaptivefilteralgorithmstoimprovetheirconvergencespeedinasparseenvironment[9,16–18].However,theseapproachesaremainlydesignedfornonproportionateadaptivealgorithms.Ontheotherhand,toutilizetheadvantagesoftheNLMSalgorithm,suchasstableperformanceandlowcomplexity,theproportionateHindawi Publishing Corporatione Scientiﬁc World JournalVolume 2014, Article ID 572969, 9 pageshttp://dx.doi.org/10.1155/2014/5729692TheScientificWorldJournalnormalizedleast-mean-square(PNLMS)algorithmhasbeenproposedandstudiedtoexploitthesparsityinnature[19]andhasbeenappliedtoechocancellationintelephonenetworks.AlthoughthePNLMSalgorithmcanutilizethesparsitychar-acteristicsofasparsesignalandobtainfasterconvergenceattheinitialstagebyassigningindependentmagnitudestotheactivetaps,theconvergencespeedisreducedbyevenmorethanthatoftheNLMSalgorithmfortheinactivetapsaftertheactivetapsconverge.Consequently,severalalgorithmshavebeenproposedtoimprovetheconvergencespeedofthePNLMSalgorithm[20–27],whichincludetheuseofthe𝑙1-normtechniqueandavariablestepsize.AlthoughthesealgorithmshavesignificantlyimprovedtheconvergencespeedofthePNLMSalgorithm,theystillconvergeslowlyaftertheactivetapsconverge.Inaddition,someofthemareinferiortotheNLMSandPNLMSalgorithmsintermsofthesteady-stateerrorwhenthesparsitydecreases.Fromthesepreviouslyproposedsparsesignalestimationalgorithms,weknowthattheZAalgorithmsmainlyexertapenaltyontheinactivechanneltapsthroughtheintegrationofthe𝑙1-normconstraintintothecostfunctionofthestandardLMSalgorithmstoachievebetterestimationperformance,whilethePNLMSalgorithmupdateseachfiltercoefficientwithanindependentstepsize,whichimprovestheconvergenceoftheactivetaps.MotivatedbytheCStheory[13,14]andZAtechnique[15–18],weproposean𝑙𝑝-norm-constrainedPNLMS(LP-PNLMS)algorithmthatincorporatesthe𝑙𝑝-normintothecostfunctionofthePNLMSalgorithm,resultinginanimprovedproportionateadaptivealgorithm.ThedifferencebetweentheproposedLP-PNLMSalgorithmandtheZAalgorithmsisthatthegain-matrix-weighted𝑙𝑝-normisusedinourproposedLP-PNLMSalgorithminsteadofthegeneral𝑙1-normtoexpandtheapplicationofZAalgorithms[15].Also,thisintegrationisequivalenttoaddingazeroattractorintheiterationsofthePNLMSalgorithmtoobtainthebenefitsofboththePNLMSandZAalgorithms.Thus,ourproposedLP-PNLMSalgorithmcanachievefastconvergenceattheinitialstagefortheactivetaps.Aftertheconvergenceoftheseactivetaps,theZAtechniqueintheLP-PNLMSalgorithmactsasanotherforcetoattracttheinactivetapstozerotoarresttheslowconvergenceofthePNLMSalgorithm.Furthermore,ourproposedLP-PNLMSalgorithmachievesalowermeansquareerrorthanthePNLMSalgorithmanditsrelatedimprovedalgorithms,suchastheimprovedPNLMS(IPNLMS)[20]and𝜇-lawPNLMS(MPNLMS)[21]algo-rithms.Inthisstudy,ourproposedLP-PNLMSalgorithmisverifiedoverasparsemultipathchannelbycomparisonwiththeNLMS,PNLMS,IPNLMS,andMPNLMSalgorithms.ThesimulationresultsdemonstratethattheLP-PNLMSalgorithmachievesbetterchannelestimationperformanceintermsofbothconvergencespeedandsteady-statebehaviorforsparsechannelestimation.Theremainderofthispaperisorganizedasfollows.Section2brieflyreviewsthestandardNLMS,PNLMS,andimprovedPNLMSalgorithms,includingtheIPNLMSandMPNLMSalgorithms.InSection3,wedescribeindetailtheproposedLP-PNLMSalgorithm,whichemploystheLagrangemultipliermethod.InSection4,theestima-tionperformanceoftheproposedLP-PNLMSalgorithmisverifiedoversparsechannelsandcomparedwithothercommonlyusedalgorithms.Finally,thispaperisconcludedinSection5.2.RelatedChannelEstimationAlgorithms2.1.NormalizedLeast-Mean-SquareAlgorithm.Inthissec-tion,wefirstconsiderthesparsemultipathcommunicationsystemshowninFigure1todiscussthechannelestimationalgorithms.Theinputsignalx(𝑛)=[𝑥(𝑛),𝑥(𝑛−1),...,𝑥(𝑛−𝑁+1)]𝑇containingthe𝑁mostrecentsamplesistransmittedoverafiniteimpulseresponse(FIR)channelwithchannelimpulseresponse(CIR)h=[ℎ0,ℎ1,...,ℎ𝑁−1]𝑇,where(⋅)𝑇denotesthetranspositionoperation.Thentheoutputsignalofthechanneliswrittenasfollows:𝑦(𝑛)=h𝑇x(𝑛),(1)wherehisasparsechannelvectorwith𝐾dominantactivetapswhosemagnitudesarelargerthanzeroand(𝑁−𝐾)inactivetapswhosemagnitudesarezeroorclosetozerowith𝐾≪𝑁.Toestimatetheunknownsparsechannelh,anNLMSalgorithmusestheinputsignalx(𝑛),theoutputsignal𝑦(𝑛),andtheinstantaneousestimationerror𝑒(𝑛),whichisgivenby𝑒(𝑛)=𝑑(𝑛)−̂h𝑇(𝑛)x(𝑛),(2)wherêh(𝑛)istheNLMSadaptivechannelestimatoratinstant𝑛,𝑑(𝑛)=𝑦(𝑛)+V(𝑛),andV(𝑛)isanadditivenoiseatthere-ceiver.TheupdatefunctionoftheNLMSchannelestimationalgorithmisexpressedaŝh(𝑛+1)=̂h(𝑛)+𝜇NLMS𝑒(𝑛)x(𝑛)x𝑇(𝑛)x(𝑛)+𝛿NLMS,(3)where𝜇NLMSisthestepsizewith0<𝜇NLMS<2and𝛿NLMSisasmallpositiveconstantusedtoavoiddivisionbyzero.2.2.ProportionateNormalizedLeast-Mean-SquareAlgorithm.ThePNLMSalgorithm,whichisanNLMSalgorithmim-provedbytheuseofaproportionatetechnique,hasbeenpro-posedforsparsesystemidentificationandechocancellation.Inthisalgorithm,eachtapisassignedanindividualstepsize,whichisobtainedfromthepreviousestimationofthefiltercoefficient.Accordingtothegainallocationruleinthisalgorithm,thegreaterthemagnitudeofthetap,thelargerthestepsizeassignedtoit,andhencetheactivetapsconvergequickly.TheupdatefunctionofthePNLMSalgorithm[19]isdescribedbythefollowingequationwithreferencetoFigure1:̂h(𝑛+1)=̂h(𝑛)+𝜇PNLMS𝑒(𝑛)G(𝑛)x(𝑛)x𝑇(𝑛)G(𝑛)x(𝑛)+𝛿PNLMS.(4)Here,G(𝑛),whichdenotesasthegainmatrix,isadiagonalmatrixthatmodifiesthestepsizeofeachtap,𝜇PNLMSistheTheScientificWorldJournal3Input signalUnknown FIR channelOutput signalAdditive noiseEstimated FIR channelAdaptive algorithmsAdaptive channel estimationx(n)̂h(n)e(n)̂y(n)y(n)(n)d(n)+++−∑∑hFigure1:Typicalsparsemultipathcommunicationsystem.globalstepsizeofthePNLMSalgorithm,and𝛿PNLMS=𝛿2𝑥/𝑁isaregularizationparametertopreventdivisionbyzeroattheinitializationstage,where𝛿2𝑥isthepoweroftheinputsignalx(𝑛).InthePNLMSalgorithm,thegainmatrixG(𝑛)isgivenbyG(𝑛)=diag(𝑔0(𝑛),𝑔1(𝑛),...,𝑔𝑁−1(𝑛)),(5)wheretheindividualgain𝑔𝑖(𝑛)isdefinedas𝑔𝑖(𝑛)=𝛾𝑖(𝑛)∑𝑁−1𝑖=0𝛾𝑖(𝑛),0≤𝑖≤𝑁−1(6)with𝛾𝑖(𝑛)=max[𝜌𝑔max[𝛿𝑝,󵄨󵄨󵄨󵄨󵄨̂ℎ0(𝑛)󵄨󵄨󵄨󵄨󵄨,󵄨󵄨󵄨󵄨󵄨̂ℎ1(𝑛)󵄨󵄨󵄨󵄨󵄨,...,󵄨󵄨󵄨󵄨󵄨̂ℎ𝑁−1(𝑛)󵄨󵄨󵄨󵄨󵄨],󵄨󵄨󵄨󵄨󵄨̂ℎ𝑖(𝑛)󵄨󵄨󵄨󵄨󵄨],(7)wheretheparameters𝛿𝑝and𝜌𝑔arepositiveconstantswithtypicalvaluesof𝛿𝑝=0.01and𝜌𝑔=5/𝑁.𝛿𝑝isusedtoregularizetheupdatingattheinitialstagewhenallthetapsareinitializedtozero,and𝜌𝑔isusedtoprevent̂ℎ𝑖(𝑛)fromstallingwhenitismuchsmallerthanthelargestcoefficient.2.3.ImprovedProportionateNormalizedLeast-Mean-SquareAlgorithms2.3.1.IPNLMSAlgorithm.TheIPNLMSalgorithmisatypeofPNLMSalgorithmusedtoimprovetheconvergencespeedofthePNLMSalgorithm.ItisacombinationofthePNLMSandNLMSalgorithmswiththerelativesignificanceofeachcoefficientcontrolledbyafactor𝛼.TheIPNLMSalgorithm[20]adoptsthe𝑙1-normtoenablethesmoothselectionof(7),andtheupdateequationoftheIPNLMSalgorithmisexpressedaŝh(𝑛+1)=̂h(𝑛)−𝜇IPNLMS𝑒(𝑛)K(𝑛)x(𝑛)x𝑇(𝑛)K(𝑛)x(𝑛)+𝛿IPNLMS,(8)whereK(𝑛)=diag(𝑘0(𝑛),𝑘1(𝑛),...,𝑘𝑁−1(𝑛))isadiagonalmatrixusedtoadjustthestepsizeoftheIPNLMSalgorithm,where𝑘𝑗(𝑛)=1−𝛼2𝑁+(1+𝛼)󵄨󵄨󵄨󵄨󵄨̂ℎ𝑗(𝑛)󵄨󵄨󵄨󵄨󵄨2󵄩󵄩󵄩󵄩󵄩̂h(𝑛)󵄩󵄩󵄩󵄩󵄩1+𝜀,0≤𝑗≤𝑁−1(9)forasmallpositiveconstant𝜀and−1≤𝛼≤1.Attheinitialstage,thestepsizeismultipliedby(1−𝛼)/2𝑁,sinceallthefiltercoefficientsareinitializedtozero.Thus,intheIPNLMSalgorithm,aregularizationparameter𝛿IPNLMSisintroduced,whichisgivenby𝛿IPNLMS=1−𝛼2𝑁𝛿NLMS.(10)WecanseethattheIPNLMSisidenticaltotheNLMSalgorithmfor𝛼=−1,whiletheIPNLMSbehavesidenticallytothePNLMSalgorithmwhen𝛼=1.Inpracticalengineer-ingapplications,asuitablevaluefor𝛼is0or−0.5.2.3.2.MPNLMSAlgorithm.The𝜇-lawPNLMSalgorithm(MPNLMS)isanotherenhancementofthePNLMSalgo-rithmthatutilizesthelogarithmofthemagnitudesofthefiltercoefficientsinsteadofusingthemagnitudesdirectlyinthePNLMSalgorithm[21].TheupdateequationisthesameasthatinthePNLMSalgorithmgivenby(4).IntheMPNLMSalgorithm,𝛾𝑖(𝑛)=max[𝜌𝑔max[𝛿𝑝𝐹(󵄨󵄨󵄨󵄨󵄨̂ℎ0(𝑛)󵄨󵄨󵄨󵄨󵄨),𝐹(󵄨󵄨󵄨󵄨󵄨̂ℎ1(𝑛)󵄨󵄨󵄨󵄨󵄨),...,𝐹(󵄨󵄨󵄨󵄨󵄨̂ℎ𝑁−1(𝑛)󵄨󵄨󵄨󵄨󵄨)],𝐹(󵄨󵄨󵄨󵄨󵄨̂ℎ𝑖(𝑛)󵄨󵄨󵄨󵄨󵄨)],(11)where𝐹(󵄨󵄨󵄨󵄨󵄨̂ℎ𝑖(𝑛)󵄨󵄨󵄨󵄨󵄨)=log(1+𝜗󵄨󵄨󵄨󵄨󵄨̂ℎ𝑖(𝑛)󵄨󵄨󵄨󵄨󵄨),(12)where𝜗isalargepositiveconstantrelatedtotheestimationaccuracyrequirement,typically𝜗=1000.3.ProposedLP-PNLMSAlgorithmInthissection,weproposeanLP-PNLMSalgorithmbyincorporatingthe𝑙𝑝-normintothecostfunctionofthePNLMSalgorithmtocreateazeroattractor,makingitatypeofZAalgorithm.ThedifferencebetweentheLP-PNLMSalgorithmandgeneralZAalgorithmsisthatthegain-matrix-weighted𝑙𝑝-normistakenintoaccountindesigningthezeroattractor.Ontheotherhand,theproposedLP-PNLMSalgorithmisbasedonthecommonlyusedPNLMSalgorithm,whichisalsoasparsechannelestimationalgorithmandcanimprovetheconvergencefortheactivetaps.Regarding4TheScientificWorldJournalchannelestimation,thepurposeoftheLP-PNLMSalgorithmistominimize(̂h(𝑛+1)−̂h(𝑛))𝑇G−1(𝑛)×(̂h(𝑛+1)−̂h(𝑛))+𝛾LP󵄩󵄩󵄩󵄩󵄩G−1(𝑛)̂h(𝑛+1)󵄩󵄩󵄩󵄩󵄩𝑝subjectto𝑑(𝑛)−̂h𝑇(𝑛+1)x(𝑛)=0,(13)whereG−1(𝑛)istheinverseofthegainmatrixG(𝑛)inthePNLMSalgorithm,𝛾LP>0isaverysmallconstantusedtobalancetheestimationerrorandthesparse𝑙𝑝-normpenaltyof̂h(𝑛+1),‖⋅‖𝑝isthe𝑝-normdefinedas‖̂h‖𝑝=(∑𝑖̂ℎ𝑝𝑖)1/𝑝,and0≤𝑝≤1.Notethatin(13),weintroducean𝑙𝑝-normpenaltytôh(𝑛+1)afterscalingthegainmatrixbyG−1(𝑛),whichisdifferentfromthepreviouslyproposedZALMSalgorithms.Tominimize(13),theLagrangemultipliermethodisadopted,andthecostfunction𝐽LP(𝑛+1)oftheproposedLP-PNLMSalgorithmisexpressedas𝐽LP(𝑛+1)=(̂h(𝑛+1)−̂h(𝑛))𝑇G−1(𝑛)×(̂h(𝑛+1)−̂h(𝑛))+𝛾LP󵄩󵄩󵄩󵄩󵄩G−1̂h(𝑛+1)󵄩󵄩󵄩󵄩󵄩𝑝+𝜆(𝑑(𝑛)−̂h𝑇(𝑛+1)x(𝑛)),(14)where𝜆istheLagrangemultiplier.Bycalculatingthegradientofthecostfunction𝐽LP(𝑛+1)oftheLP-PNLMSalgorithmandassuminĝh(𝑛+1)=̂h(𝑛)inthesteadystage,wehave𝜕𝐽LP(𝑛+1)𝜕̂h(𝑛+1)=0,𝜕𝐽LP(𝑛+1)𝜕𝜆=0,(15)̂h(𝑛+1)=̂h(𝑛)+𝜆G(𝑛)x(𝑛)−𝛾LP󵄩󵄩󵄩󵄩󵄩̂h(𝑛)󵄩󵄩󵄩󵄩󵄩1−𝑝𝑝sgn(̂h(𝑛))󵄨󵄨󵄨󵄨󵄨̂h(𝑛)󵄨󵄨󵄨󵄨󵄨1−𝑝.(16)Inpractice,weneedtointroduceasmallpositiveconstantintothefinaltermin(16)tocopewiththesituationthatanentryof̂h(𝑛)approacheszero,whichisthecaseforasparseCIRatinitialization.Thentheupdateequation(16)oftheLP-PNLMSalgorithmismodifiedtôh(𝑛+1)=̂h(𝑛)+𝜆G(𝑛)x(𝑛)−𝛾LP󵄩󵄩󵄩󵄩󵄩̂h(𝑛)󵄩󵄩󵄩󵄩󵄩1−𝑝𝑝sgn(̂h(𝑛))󵄨󵄨󵄨󵄨󵄨̂h(𝑛)󵄨󵄨󵄨󵄨󵄨1−𝑝+𝜀𝑝,(17)where𝜀𝑝isasmallvaluetopreventdivisionbyzero.Bymultiplyingbothsidesof(17)byx𝑇(𝑛),weobtainx𝑇(𝑛)̂h(𝑛+1)=x𝑇(𝑛)̂h(𝑛)+𝜆x𝑇(𝑛)G(𝑛)x(𝑛)−𝛾LPx𝑇(𝑛)󵄩󵄩󵄩󵄩󵄩̂h(𝑛)󵄩󵄩󵄩󵄩󵄩1−𝑝𝑝sgn(̂h(𝑛))󵄨󵄨󵄨󵄨󵄨̂h(𝑛)󵄨󵄨󵄨󵄨󵄨1−𝑝+𝜀𝑝.(18)From(2),(15),and(17),weobtain𝑒(𝑛)=−𝛾LPx𝑇(𝑛)󵄩󵄩󵄩󵄩󵄩̂h(𝑛)󵄩󵄩󵄩󵄩󵄩1−𝑝𝑝sgn(̂h(𝑛))󵄨󵄨󵄨󵄨󵄨̂h(𝑛)󵄨󵄨󵄨󵄨󵄨1−𝑝+𝜀𝑝+𝜆x𝑇(𝑛)G(𝑛)x(𝑛).(19)Then,theLagrangemultiplier𝜆isgivenasfollowsbysolving(19):𝜆=(𝑒(𝑛)+𝛾LPx𝑇(𝑛)󵄩󵄩󵄩󵄩󵄩̂h(𝑛)󵄩󵄩󵄩󵄩󵄩1−𝑝𝑝sgn(̂h(𝑛))󵄨󵄨󵄨󵄨󵄨̂h(𝑛)󵄨󵄨󵄨󵄨󵄨1−𝑝+𝜀𝑝)×(x𝑇(𝑛)G(𝑛)x(𝑛))−1.(20)Substituting(20)into(17),wehavêh(𝑛+1)=̂h(𝑛)−𝛾LP󵄩󵄩󵄩󵄩󵄩̂h(𝑛)󵄩󵄩󵄩󵄩󵄩1−𝑝𝑝sgn(̂h(𝑛))󵄨󵄨󵄨󵄨󵄨̂h(𝑛)󵄨󵄨󵄨󵄨󵄨1−𝑝+𝜀𝑝+((𝑒(𝑛)+𝛾LPx𝑇(𝑛)󵄩󵄩󵄩󵄩󵄩̂h(𝑛)󵄩󵄩󵄩󵄩󵄩1−𝑝𝑝sgn(̂h(𝑛))󵄨󵄨󵄨󵄨󵄨̂h(𝑛)󵄨󵄨󵄨󵄨󵄨1−𝑝+𝜀𝑝)×(x𝑇(𝑛)G(𝑛)x(𝑛))−1)G(𝑛)x(𝑛)=̂h(𝑛)+𝑒(𝑛)G(𝑛)x(𝑛)x𝑇(𝑛)G(𝑛)x(𝑛)−𝛾LP{I−G(𝑛)x(𝑛)x𝑇(𝑛)x𝑇(𝑛)G(𝑛)x(𝑛)}×󵄩󵄩󵄩󵄩󵄩̂h(𝑛)󵄩󵄩󵄩󵄩󵄩1−𝑝𝑝sgn(̂h(𝑛))󵄨󵄨󵄨󵄨󵄨̂h(𝑛)󵄨󵄨󵄨󵄨󵄨1−𝑝+𝜀𝑝.(21)ItwasfoundthatthemagnitudesoftheelementsinthematrixG(𝑛)x(𝑛)x𝑇(𝑛){x𝑇(𝑛)G(𝑛)x(𝑛)}−1aremuchsmallerTheScientificWorldJournal5than1forbroadbandmultipathchannelestimation.There-fore,theupdateequation(21)oftheproposedLP-PNLMSalgorithmisrewrittenaŝh(𝑛+1)=̂h(𝑛)+𝑒(𝑛)G(𝑛)x(𝑛)x𝑇(𝑛)G(𝑛)x(𝑛)−𝛾LP󵄩󵄩󵄩󵄩󵄩̂h(𝑛)󵄩󵄩󵄩󵄩󵄩1−𝑝𝑝sgn(̂h(𝑛))󵄨󵄨󵄨󵄨󵄨̂h(𝑛)󵄨󵄨󵄨󵄨󵄨1−𝑝+𝜀𝑝.(22)Here,weneglecttheeffectsofthematrixG(𝑛)x(𝑛)x𝑇(𝑛){x𝑇(𝑛)G(𝑛)x(𝑛)}−1andassumethatthefilterorderislarge.SimilarlytothePNLMSalgorithm,astepsize𝜇LPisintro-ducedtobalancetheconvergencespeedandthesteady-stateerroroftheproposedLP-PNLMSalgorithm,andasmallpositiveconstant𝜀LP=𝛿2𝑥/𝑁isemployedtopreventdivisionbyzero.Thus,theupdatefunction(22)canbemodifiedtôh(𝑛+1)=̂h(𝑛)+𝜇LP𝑒(𝑛)G(𝑛)x(𝑛)x𝑇(𝑛)G(𝑛)x(𝑛)+𝜀LP−𝜌LP󵄩󵄩󵄩󵄩󵄩̂h(𝑛)󵄩󵄩󵄩󵄩󵄩1−𝑝𝑝sgn(̂h(𝑛))󵄨󵄨󵄨󵄨󵄨̂h(𝑛)󵄨󵄨󵄨󵄨󵄨1−𝑝+𝜀𝑝=̂h(𝑛)+𝜇LP𝑒(𝑛)G(𝑛)x(𝑛)x𝑇(𝑛)G(𝑛)x(𝑛)+𝜀LP−𝜌LPT(𝑛),(23)where𝜌LP=𝜇LP𝛾LPandT(𝑛)=‖̂h(𝑛)‖1−𝑝𝑝sgn(̂h(𝑛)){|̂h(𝑛)|1−𝑝+𝜀𝑝}−1.Comparingtheupdatefunction(23)oftheproposedLP-PNLMSalgorithmwiththeupdatefunction(4)ofthePNLMSalgorithm,weseethatourproposedLP-PNLMSalgorithmhastheadditionalterm𝛾LPT(𝑛),alsodefinedasthezeroattractor,whichattractsthesmallchanneltapstozerowithhighprobability.Moreover,theZAstrengthofthiszeroattractoriscontrolledby𝜌LP.Inotherwords,inourproposedLP-PNLMSalgorithm,thegainmatrixG(𝑛)assignsalargestepsizetotheactivechanneltapsofthesparsechannel,whilethezeroattractormainlyexertsthe𝑙𝑝-penaltyontheinactivetapswhosetapsarezeroorclosetozero.Thus,ourproposedLP-PNLMSalgorithmcanfurtherimprovetheconvergencespeedofthePNLMSalgorithmaftertheconvergenceofthelargeactivetaps.4.ResultsandDiscussionsInthissection,wepresenttheresultsofcomputersimulationscarriedouttoillustratethechannelestimationperformanceoftheproposedLP-PNLMSalgorithmoverasparsemulti-pathcommunicationchannelandcompareitwiththoseofthepreviouslyproposedIPNLMS,MPNLMS,PNLMS,andNLMSalgorithms.Here,weconsiderasparsechannelhwhoselength𝑁is64or128andwhosenumberofdominantactivetaps𝐾issettothreedifferentsparsitylevels,namely,𝐾=2,4and8,similartopreviousstudies[6,22,25,26].ThedominantactivechanneltapsareobtainedfromaGaussian00.10.20.30.40.50.60.7Channel tap indexMagnitude0102030405060Figure2:Typicalsparsemultipathchannel.distributionwith‖h‖22=1,andthepositionsofthedominantchanneltapsarerandomlyspacedalongthelengthofthechannel.Theinputsignalx(𝑛)ofthechannelisaGaussianrandomsignalwhiletheoutputofthechanneliscorruptedbyanindependentwhiteGaussiannoiseV(𝑛).Anexampleofatypicalsparsemultipathchannelwithachannellengthof𝑁=64andasparsitylevelof𝐾=3isshowninFigure2.Inthesimulations,thepowerofthereceivedsignalis𝐸𝑏=1,whilethenoisepowerisgivenby𝛿2Vandthesignal-to-noiseratioisdefinedasSNR=10log(𝐸𝑏/𝛿2V).Inallthesimulations,thedifferencebetweentheactualandestimatedchannelsbasedonthesparsity-awarealgorithmsandthesparsechannelmentionedaboveisevaluatedbytheMSEdefinedasfollows:MSE(𝑛)=10log10E{󵄩󵄩󵄩󵄩󵄩h−̂h(𝑛)󵄩󵄩󵄩󵄩󵄩22}(dB).(24)Inthesesimulations,thesimulationparametersarecho-sentobe𝜇NLMS=𝜇PNLMS=𝜇IPNLMS=𝜇LP=0.5,𝛿NLMS=0.01,𝜀=0.001,𝛼=0,𝜀𝑝=0.05,𝜌LP=1×10−5,𝛿𝑝=0.01,𝜌𝑔=5/𝑁,𝜗=1000,𝑝=0.5,andSNR=30dB.Whenwechangeoneoftheseparameters,theotherparametersremainconstant.4.1.EstimationPerformanceoftheProposedLP-PNLMSAlgorithm4.1.1.EffectsofParametersontheProposedLP-PNLMSAlgo-rithm.IntheproposedLP-PNLMSalgorithm,therearetwoextraparameters,𝑝and𝜌LP,comparedwiththePNLMSalgorithm,whichareintroducedtodesignthezeroattractor.Next,weshowhowthesetwoparametersaffecttheproposedLP-PNLMSalgorithmoverasparsechannelwith𝑁=64or128and𝐾=4.Thesimulationresultsfordifferentvaluesof𝜌LPand𝑝areshowninFigures3and4,respectively.FromFigure3(a),wecanseethatthesteady-stateerroroftheLP-PNLMSalgorithmdecreaseswithdecreasing𝜌LPwhen6TheScientificWorldJournal0510IterationsMSE (dB)0200400600800100012001400160018002000−5−10−15−20−25−30−35−40𝜌LP=4×10−5𝜌LP=3×10−5𝜌LP=2×10−5𝜌LP=1×10−5𝜌LP=2×10−6𝜌LP=2×10−7(a)𝑁=640510IterationsMSE (dB)0200400600800100012001400160018002000−5−10−15−20−25−30−35−40𝜌LP=4×10−5𝜌LP=3×10−5𝜌LP=2×10−5𝜌LP=1×10−5𝜌LP=2×10−6𝜌LP=2×10−7(b)𝑁=128Figure3:Effectsof𝜌LPontheproposedLP-PNLMSalgorithm.𝜌LP≥2×10−6,whileitincreasesagainwhen𝜌LPislessthan2×10−6.Furthermore,theconvergencespeedoftheLP-PNLMSalgorithmrapidlydecreaseswhen𝜌LPislessthan1×10−5.Thisisbecauseasmall𝜌LPresultsinalowZAstrength,whichconsequentlyreducestheconvergencespeed.Inthecaseof𝑁=128showninFigure3(b),weobservethatboththeconvergencespeedandthesteady-stateperformanceareimprovedwithdecreasing𝜌LPfor𝜌LP≥1×10−5.When𝜌LP<1×10−5,theconvergencespeedoftheLP-PNLMSalgorithmdecreaseswhilethesteady-stateerrorremainsconstant.Figure4demonstratestheeffectsoftheparameter𝑝.WecanseefromFigure4(a)thattheconvergencespeedoftheproposedLP-PNLMSalgorithmrapidlydecreaseswithincreasing𝑝for𝑁=64.Moreover,thesteady-stateerrorisreducedwith𝑝rangingfrom0.45to0.5,whileitremainsconstantfor𝑝=0.6,0.7,and0.8.However,thesteady-stateperformancefor𝑝=1isinferiortothatfor𝑝=0.8.ThisisbecausetheproposedLP-PNLMSalgorithmisan𝑙1-norm-penalizedPNLMSalgorithm,whichcannotdistin-guishbetweenactivetapsandinactivetaps,reducingitsconvergencespeedandsteady-stateperformance.When𝑁=128,asshowninFigure4(b),thesteady-stateperformanceisimprovedas𝑝increasesfrom0.45to0.6.Thus,weshouldcarefullyselecttheparameters𝜌LPand𝑝tobalancetheconvergencespeedandsteady-stateperformancefortheproposedLP-PNLMSalgorithm.4.1.2.EffectsofSparsityLevelontheProposedLP-PNLMSAlgo-rithm.OnthebasisoftheresultsdiscussedinSection4.1.1forourproposedLP-PNLMSalgorithm,wechoose𝑝=0.5and𝜌LP=1×10−5toevaluatethechannelestimationperformanceoftheLP-PNLMSalgorithmoverasparsechannelwithdifferentchannellengthsof𝑁=64and128,forwhichtheobtainedsimulationresultsaregiveninFigures5and6,respectively.FromFigure5,weseethatourproposedLP-PNLMSalgorithmhasthesameconvergencespeedasthePNLMSalgorithmattheinitialstage.TheproposedLP-PNLMSalgorithmconvergesfasterthanthePNLMSalgorithmaswellastheIPNLMSandNLMSalgo-rithmsforallsparsitylevels𝐾,whileitsconvergenceisslightlyslowerthanthatoftheMPNLMSalgorithmbeforeitreachesasteadystage.However,theproposedLP-PNLMSalgorithmhasthesmalleststeady-stateerrorfor𝑁=64.When𝑁=128,weseefromFigure6thatourproposedLP-PNLMSalgorithmnotonlyhasthehighestconvergencespeedbutalsopossessesthebeststeady-stateperformance.Thisisbecausewithincreasingsparsity,ourproposedLP-PNLMSalgorithmattractstheinactivetapstozeroquicklyandhencetheconvergencespeedissignificantlyimproved,whilethepreviouslyproposedPNLMSalgorithmsmainlyadjustthestepsizeoftheactivetapsandthustheyonlyimpactontheconvergencespeedattheearlyiterationstage.Additionally,weseefromFigures5and6thatboththeconvergencespeedandthesteady-stateperformanceofallthePNLMSalgorithmsdeterioratewhenthesparsitylevel𝐾increasesforboth𝑁=64and128.Inparticular,when𝐾=8,theconvergencespeedsofthePNLMSandIPNLMSalgorithmsaregreaterthanthatoftheNLMSalgorithmattheearlyiterationstage,whileafterthisfastinitialconvergence,theirconvergencespeedsdecreasetolessthanthatoftheNLMSalgorithmbeforereachingasteadyTheScientificWorldJournal70510IterationsMSE (dB)0200400600800100012001400160018002000−5−10−15−20−25−30−35−40p=0.45p=0.5p=0.6p=0.7p=0.8p=1(a)𝑁=640510IterationsMSE (dB)0200400600800100012001400160018002000−5−10−15−20−25−30−35−40p=0.45p=0.5p=0.6p=0.7p=0.8p=1(b)𝑁=128Figure4:Effectsof𝑝ontheproposedLP-PNLMSalgorithm.stage.Furthermore,weobservethattheMPNLMSalgorithmissensitivetothelength𝑁ofthechannel,anditsconvergencespeedfor𝑁=128islessthanthatfor𝑁=64atthesamesparsitylevel𝐾andlessthanthatoftheproposedLP-PNLMSalgorithm.Thus,weconcludethatourproposedLP-PNLMSalgorithmissuperiortothepreviouslyproposedPNLMSalgorithmsintermsofboththeconvergencespeedandthesteady-stateperformancewiththeappropriateselectionoftherelatedparameters𝑝and𝜌LP.Fromtheabovediscussion,webelievethatthegain-matrix-weighted𝑙𝑝-normmethodintheLP-PNLMSalgorithmcanbeusedtofurtherimprovethechannelestimationperformanceoftheIPNLMSandMPNLMSalgorithms.4.2.ComputationalComplexity.Finally,wediscussthecom-putationalcomplexityoftheproposedLP-PNLMSalgorithmandcompareitwiththoseoftheNLMS,PNLMS,IPNLMS,andMPNLMSalgorithms.Here,thecomputationalcomplex-ityisthearithmeticcomplexity,whichincludesadditions,multiplications,anddivisions.Thecomputationalcomplex-itiesoftheproposedLP-PNLMSalgorithmandtherelatedPNLMSandNLMSalgorithmsareshowninTable1.FromTable1,weseethatthecomputationalcomplexityofourproposedLP-PNLMSalgorithmisslightlyhigherthanthoseoftheMPNLMSandPNLMSalgorithms,whichisduetothecalculationofthegradientofthe𝑙𝑝-norm.Furthermore,theMPNLMSalgorithmhasanadditionallogarithmoperation,whichincreasesitscomplexitybutisnotincludedinTable1.However,theLP-PNLMSalgorithmnoticeablyincreasestheconvergencespeedandsignificantlyTable1:Computationalcomplexity.AlgorithmsAdditionsMultiplicationsDivisionsNLMS3𝑁3𝑁+11PNLMS4𝑁+36𝑁+3𝑁+2IPNLMS4𝑁+75𝑁+5𝑁+2MPNLMS5𝑁+37𝑁+3𝑁+3LP-PNLMS4𝑁+49𝑁+42𝑁+2improvesthesteady-stateperformanceofthePNLMSalgo-rithm.Inaddition,italsohasahigherconvergencespeedandlowersteady-stateerrorthantheIPNLMSandMPNLMSalgorithmswhenthechannellengthislarge.5.ConclusionInthispaper,wehaveproposedanLP-PNLMSalgorithmtoexploitthesparsityofbroadbandmultipathchannelsandtoimproveboththeconvergencespeedandsteady-stateperfor-manceofthePNLMSalgorithm.Thisalgorithmwasmainlydevelopedbyincorporatingthegain-matrix-weighted𝑙𝑝-normintothecostfunctionofthePNLMSalgorithm,whichsignificantlyimprovesitsconvergencespeedandsteady-stateperformance.ThesimulationresultsdemonstratedthatourproposedLP-PNLMSalgorithm,whichhasanacceptableincreaseincomputationalcomplexity,increasestheconver-gencespeedandreducesthesteady-stateerrorcomparedwiththepreviouslyproposedPNLMSalgorithms.8TheScientificWorldJournalMSE (dB)NLMSPNLMSIPNLMSMPNLMSLP-PNLMSIterations05001000150020002500−5−10−15−20−25−30−35−40−450105(a)𝐾=2NLMSPNLMSIPNLMSMPNLMSLP-PNLMS0510IterationsMSE (dB)05001000150020002500−5−10−15−20−25−30−35−40(b)𝐾=4NLMSPNLMSIPNLMSMPNLMSLP-PNLMSIterationsMSE (dB)051005001000150020002500−5−10−15−20−25−30−35−40(c)𝐾=8Figure5:EffectsofsparsityontheproposedLP-PNLMSalgorithmfor𝑁=64.0510MSE (dB)Iterations05001000150020002500−5−10−15−20−25−30−35−40−45NLMSPNLMSIPNLMSMPNLMSLP-PNLMS(a)𝐾=2MSE (dB)0510Iterations05001000150020002500−5−10−15−20−25−30−35−40NLMSPNLMSIPNLMSMPNLMSLP-PNLMS(b)𝐾=4MSE (dB)0510Iterations05001000150020002500−5−10−15−20−25−30−35−40NLMSPNLMSIPNLMSMPNLMSLP-PNLMS(c)𝐾=8Figure6:EffectsofsparsityontheproposedLP-PNLMSalgorithmfor𝑁=128.TheScientificWorldJournal9ConflictofInterestsTheauthorsdeclarethatthereisnoconflictofinterestsregardingthepublicationofthispaper.
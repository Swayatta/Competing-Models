Effect Generation Based on Causal Reasoning

Feiteng Mu1, Wenjie Li1, Zhipeng Xie2

1The Department of Computing, The Hong Kong Polytechnic University, Hong Kong

2School of Computer Science, Fudan University, Shanghai, China

csfmu,cswjli@comp.polyu.edu.hk,xiezp@fudan.edu.cn

Abstract

Causal reasoning aims to predict the future
scenarios that may be caused by the observed
actions. However, existing causal reasoning
methods deal with causalities on the word
level. In this paper, we propose a novel event-
level causal reasoning method and demon-
strate its use in the task of effect generation. In
particular, we structuralize the observed cause-
effect event pairs into an event causality net-
work, which describes causality dependencies.
Given an input cause sentence, a causal sub-
graph is retrieved from the event causality net-
work and is encoded with the graph attention
mechanism, in order to support better reason-
ing of the potential effects. The most proba-
ble effect event is then selected from the causal
subgraph and is used as guidance to generate
an effect sentence. Experiments show that our
method generates more reasonable effect sen-
tences than various well-designed competitors.
Introduction

1
Causal reasoning is the process of observing an
action and reasoning future scenarios that may be
potentially caused by it (Radinsky et al., 2012).
Earlier causal reasoning methods (Roemmele et al.,
2011; Luo et al., 2016) collect causally related
word pairs (e.g., earthquake→tsunami) to build
the statistical models of causality, and then pre-
dict effects words for given cause words. Recently,
(Xie and Mu, 2019) uses causal embedding to pre-
dict possible effect words of the input causes. (Li
et al., 2020) proposed the lexically-constrained
beam-search to generate possible effects given pro-
vided word guidance. However, all these methods
tend to reason causalities at word-level.

Causalities between word pairs are not always
self-contained (i.e., intelligible) when they are
extracted without the context (Hashimoto et al.,
2014)). For example, "quarrel→break" is not self-
contained since this is not intelligible without the
context: "They always quarrel→They break up". A

word-level causal reasoning method may only pre-
dict the unintelligible effect of "break" conditioned
"quarrel". Considering this deﬁciency, a better
way is to enhance causal reasoning with causal
events (Radinsky et al., 2012; Zhao et al., 2017;
Martin et al., 2018; Ammanabrolu et al., 2020).
However, an observed causal event is very likely
to appear only once, which brings about huge spar-
sity to causalities and great difﬁculty to the event-
level causal reasoning. To solve this problem, we
structuralize observed causal events into an event
causality network, where similar events are clus-
tered together. Given an input cause sentence, a
causal subgraph is retrieved and is encoded with
the graph attention mechanism, in order to support
better effect reasoning. As such, we are able to
predict the most reasonable effect event based on
the event causality network. The predicted effect
event contains the skeleton information, with the
detailed context neglected in the event extraction
process. So we further rewrite the predicted effect
event to an effect sentence in order to ﬁll in the
missing information.

The contributions of this paper are twofold: i) we
devise a effect generation method which is based
on causal event reasoning (EGCER) to generate
effect sentences for given input cause sentences, ii)
experiments demonstrate that our model achieves
better performances compared among various well-
designed baselines.

2 Event Causality Network Construction

In this paper, we use causal events to bridge the
causalities between input sequences and generated
sequences. Hence, we must ﬁrst collect sufﬁcient
cause-effect sentence pairs so that from each sen-
tence pair a cause-effect event pair can be eventi-
ﬁed. Then we construct an event causality network
based on the extracted causal event pairs. The
construction process includes two steps: 1) Event
Eventiﬁcation, 2) Events Structuralization.

FindingsoftheAssociationforComputationalLinguistics:EMNLP2021,pages527–533November7–11,2021.©2021AssociationforComputationalLinguistics527Event Eventiﬁcation: Following (Do et al.,
2011; Asghar, 2016; Luo et al., 2016; Hassan-
zadeh et al., 2019), we make use of a few high-
precision causal connectives to extract cause-effect
sentence pairs, for example ‘because’, ‘as a re-
sult’, etc. Then we extract causal event pairs from
causal sentence pairs based on dependency analy-
sis1. We adopt the commonly used 4-tuple event
representation (s, v, o, m) (Pichotta and Mooney,
2016) where v denotes the verb, s denotes the head
noun of the subject, o denotes the head noun of the
direct object or the adjective, and m denotes the
head noun of the prepositional or indirect object.
Events Structuralization: We structuralize the
extracted causal event pairs into an event causal-
ity network, in which semantically similar events
are clustered together. We use event abstractions
to judge whether two events are semantically sim-
ilar. The abstraction of an event is obtained by
generalizing its components to their categories in
linguistic resources. Speciﬁcally, the verb in each
event is generalized to its class in VerbNet (Schuler,
2005). The other components are generalized by
the WordNet (Miller, 1995) synset two levels up in
the inherited hypernym hierarchy. In addition, we
explicitly use the semantic-similarity based infer-
ring rule. For example, assume we have observed
that A has the same abstraction with B, and a causal
relation holds from A to C, then it is most likely to
conclude that there may be a causal relation from
B to C. Such a manipulation signiﬁcantly reduces
the sparsity of causalities in the event causality net-
work, and hence supports better reasoning about
the effect events. The weight of an edge in our
event causality network is derived by the following
rules:

1) If the edge between the event pair (ei, ej) is
extracted from the dataset, the weight wij of this
edge is wij = 1;

2) If the edge of (ei, ej) is inferred based
on the semantic-similarity between (ei, ek) and
the causal relation between (ek, ej), we have
wij = sim(ei, ek), where sim(ei, ek), calculated
by the path-similarity measure in WordNet, is the
semantic-similarity score between ei and ek.

3 Effect Generation
Task Discription: The goal of effect generation
consists of predicting the an effect event for the
input cause and rewriting the predicted effect event

1https://spacy.io/

Figure 1: The overview of EGCER.

into an effect sentence. Formally, given a cause
sentence X = {x1x2 ··· xm}, and a causal sub-
graph CG = {e1, e2,··· , eNCG}, which con-
sists of a set of events {ej = (sj, vj, oj, mj)}
(j = 1,··· , NCG) as nodes, our model ﬁrst pre-
dicts an effect event eY from CG according to
X, then rewrites eY to an effect sentence Y =
{y1y2 ··· yn}. The overview of the proposed
EGCER is illustrated in Figure 1, which consists
of two modules: 1) Effect Event Predictor, and 2)
Effect Event Rewriter.

Effect Event Predictor: Given the cause sen-
tence X, a bidirectional GRU model (Cho et al.,
2014) is used to reads the sequence X from both
−→
←−
hxi and
directions and computes hidden states
hxi
−→
←−
for the token xi. The ﬁnal hidden vectors of X is
HX = {hx1,··· , hxm}, where hxi = [
hxi].
hxi;
We then eventify the cause event from X, and
match the event abstraction in the event causal-
ity network. Once the abstraction is matched, a
L-hop causal-related subgraph CG is preserved.
The neighborhood information in CG represents
the causality tendencies, which are useful for rea-
soning the most reasonable effect event. We use
a simple graph neural network (GNN) (Kipf and
Welling, 2016; Veliˇckovi´c et al., 2017) to capture
the neighborhood information. Speciﬁcally, the l-
th layer’s vectors of ei and its neighbors are pooled
to obtain the vector of ei on the (l + 1)-th layer
with a activation function σ (ReLU by default):

zl
i = Wlel
i

el+1
i = σ(

NCG(cid:88)

j=1

(cid:80)

exp(wij(zl
i
k exp(wkj(zl
k

T · zl
j)
T · zl
j)

(1)

zl
j),

where Wl is a parameter, · denotes the inner prod-
uct of the two vectors, wij is the weight of the
edge (ei, ej), el
i is the vector of ei at l-th layer,
i = [esi; evi; eoi; emi] is the concated word em-
e0
bedding of all components of ei.
i (i = 1,··· , NCG)
of events are used to select the guided effect event

The ﬁnal hidden vector eL

528T · hX is
eY by eY = maxi csi, where csi = eL
i
the causal score between each candidate event ei
and X, hX = 1
k=1 hxk is the mean-pooling
m
representation of X.

(cid:80)m

Effect Event Rewriter: The predicted eY con-
tains the skeleton information, we want retain
all tokens of eY when generating the effect sen-
tence to avoiding the causal information carried
by eY degrading to word-level. Inspired by (Mou
et al., 2016; Martin et al., 2018), we rewrite eY =
(s, v, o, m) into the effect sentence which conforms
to the format of [_s][_v][_o][_m], where blanks in-
dicate the place words should be added to in order
to make a sentence richer in content. We use a de-
coder with attention mechanism (Bahdanau et al.,
2014) to generate words in each blank until gener-
ating the "<eos>" token.

4 Experiments
4.1 Datasets
English Wikipedia(Enwiki): We extract cause-
effect sentence pairs from the English Wikipedia
corpus2, resulting in about 80K pairs. We split all
pairs into training/validation/test with the ratio of
8:1:1, and tune parameters on the validation data.
The training data is used to construct the event
causality network. We retrieve 2-hop causal sub-
graphs according to input cause sentences because
it is the most commonly used setting. The percent-
age of the test samples whose gold effect events
exist in the retrieved causal subgraphs is 70.8%.

COPA Benchmark: The Choice of Plausi-
ble Alternatives (COPA) (Roemmele et al., 2011)
dataset consists of 1,000 multiple-choice questions
(500 for validation and 500 for testing) requiring
causal reasoning in order to answer correctly. Each
question is composed of a premise and two alterna-
tives, and the task is to select a more plausible alter-
native as a cause (or an effect) of the premise. We
use the most plausible alternative and its premise
to collect cause-effect sentence pairs. The COPA
causes are used to retrieve causal subgraphs from
our event causality network, leading to 186 COPA
pairs with their corresponding causal subgraphs.
The percentage of the samples whose gold effect
events exist in causal subgraphs is 11.2%. Because
there is no released training data for the COPA task,
we train all models on Enwiki and evaluate them
on COPA.

2https://dumps.wikimedia.org/enwiki/20201020/enwiki-

20201020-pages-articles.xml.bz2

4.2 Baselines and Evaluation
Baselines: We compare our method with state-of-
the-art text generation methods, including GPT2
(Radford et al., 2019), BART(Lewis et al., 2019),
CopyNet(Zhu et al., 2017) and CausalBERT(Li
et al., 2020). Details can be seen in Appendix A.

Metrics: For automatic evaluation, we use met-
rics including BLEU-4 (Papineni et al., 2002),
Distinct-n (Li et al., 2015) to evaluate the generated
effect sentences. Abstraction-Matching (AbsMat)
evaluates the percentage of the generated effect
sequences that have the same abstraction as the
corresponding gold effect sequences.

For the manual evaluation, we examine whether
the generated sequence is a plausible effect of the
input, which is denoted as plausibility (Plau). De-
tails can be seen in Appendix B.

Result: The result is shown in Table 1, where
EGCER achieves the best results. BART per-
forms better than GPT2 due to the adopted encoder-
decoder architecture. Based on the event skeletons
provided by the effect event predictor, CopyNet
and EGCER are aware of the topic which should
be generated, and hence perform better than BART
and GPT2. CopyNet performs worse than EGCER
because CopyNet cannot cover all tokens of the
retrieved event, as a result, the causal information
in the generated sequence is incomplete. We also
ﬁnd that CopyNet tends to copy an event token re-
peatedly. CausalBert performs worse than EGCER
because it is based on the word-level causal analy-
sis, which can also be found in Section 4.3. Given
the effect event, EGCER sees a more complete
scenario, hence generate a more reasonable effect
sentence.

The result of the manual evaluation is also shown
in Table 1. As for EGCER, we ﬁnd that it may
sometimes generate negation expressions or gram-
matical errors, as a result, the generated sequence
is not a plausible effect even if the retrieved event
is plausible. The proportion of the generated se-
quences in this case is about 21%. We speculate
that the errors in data preprocessing and the insufﬁ-
ciently powerful generator are the possible reasons.
In the future, we will further improve generators
in order to generate more high-quality effect sen-
tences. It can also be found that EGCER performs
far worse on COPA than on Enwiki, this is because
a great gap exists between these two datasets. How-
ever, EGCER is still superior to any other model,
which demonstrates event-level causal reasoning

529Model

GPT2
BART
CausalBERT
CopyNet
EGCER(ours)

EnWiki

COPA

BLEU-4 Distinct-1/2 AbsMat Plau BLEU-4 Distinct-1/2 AbsMat Plau
0.02
0.04
0.06
0.04
0.07

5.57/16.82
8.23/24.83
5.33/22.23
10.63/39.82
13.99/43.58

0.3
1.7
8.5
16.4
26.4

0.69
1.28
0.74
2.85
4.90

0.08
0.11
0.12
0.17
0.27

1.35
1.22
0.92
1.18
1.74

22.61/44.25
22.37/43.71
22.39/52.56
32.74/75.17
48.08/83.97

0.2
0.5
3.7
2.6
5.3

Table 1: Automatic and manual evaluation results.

contributes to the effect sentence generation.

4.3 Visualization

because they are not effect events at all. This shows
that the multi-layer GNN can well capture multi-
hop causal relationships and thus are able to select
the plausible effect events.

4.4 Ablation Study

(a) The causal scores calcu-
lated using the event vectors
on the ﬁrst layer of GNN.

(b) The causal scores calcu-
lated using the event vectors
on the second layer of GNN.

Figure 2: The darker blue indicates the higher causal
score.

Models

BLEU-4 Distinct-1/2 AbsMat

Plau

Full model
w/o weights
w/o 2nd layer
w/o GNN

4.90
4.37
3.89
2.89

13.99/43.58
14.10/42.86
13.15/41.56
13.00/42.02

26.4
23.3
20.6
18.3

0.27
0.24
0.21
0.19

Appendix C presents a case with generations of
different models. CausalBERT generates "miss-
ing bus" given "missing" as guidance. However,
from the input we can see that this person may
be in a car, therefor the generated sequence is
not an effect. That is CausalBERT, which is
based on the word-level analysis, generates causal
inconsistent sequence.
In contrast, our method
successfully predicts the expected effect event
"(he,missed,meeting)", and generates the correct
effect sentence.

We extract a part of CG according to the in-
put cause, and visualize the causal scores cs using
event vectors on the ﬁrst and second layers of GNN
respectively, as shown in Figure 2a and 2b.
In
Figure 2a, the "(was, late, work)" receives the high-
est score, followed by "(he, encountered, jam)"
and "(was, late, meeting)" in one-hop reasoning.
And, the "(leader, scolded, him)" receives the low-
est score. Noted that "(he, encountered, jam)" is
actually not an effect event. However, in Figure
2b, the "(he, missed, meeting)" receives the highest
score, followed by "(was, late, work)", "(was, late,
meeting)" and "(leader, scolded, him)" in two-hop
reasoning. The "(he, encountered, jam)" and "(rain,
is, heavy)" receive lower scores. This makes sense

Table 2: Ablation study on the Enwiki testset.

To understand the importance of the key com-
ponents of our approach, we perform an ablation
study by training multiple ablated versions of our
model, including the one without weights of edges
in the retrieved causal subgraph, the one without
the 2nd-layer of GNN, and the one without GNN.
The results are provided in Table 2. When the GNN
module is gradually ablated, the performance of
the model gradually degrades. This demonstrates
that all modules of our multi-layer GNN effectively
contribute to effect sentence generation.

5 Conclusion and Future Work

We present an event-level causal reasoning based
effect generation method to generate the plausible
effect sentences for the input cause sentences. Ex-
periments show that our method performs better
than competitors in capturing the causal seman-
tics which should be generated. In the future, we
would like to develop more effective approaches to
enhance the effect event reasoning, and more pow-
erful generators to generate the effect sentences
with higher quality.

5306 Acknowledgements
The work described in this paper was sup-
ported by and Research Grants Council of
Hong Kong(PolyU/5210919, PolyU/15207920,
PolyU/15207821), National Natural Science Foun-
dation of China (61672445, 62076212, 62076072)
and PolyU internal grants (ZVQ0). We are grate-
ful to the anonymous reviewers for their valuable
comments.


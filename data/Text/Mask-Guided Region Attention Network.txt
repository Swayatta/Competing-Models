Mask-Guided Region Attention Network

for Person Re-Identiﬁcation

Cong Zhou1 and Han Yu1,2(&)

1 Nanjing University of Posts and Telecommunications School of Computer

Science and Technology, Nanjing 210023, China

519658713@qq.com, han.yu@njupt.edu.cn

2 Jiangsu Key Lab of Big Data Security and Intelligent Processing,

Nanjing 210023, China

Abstract. Person re-identiﬁcation (ReID) is an important and practical task
which identiﬁes pedestrians across non-overlapping surveillance cameras based
on their visual features. In general, ReID is an extremely challenging task due to
complex background clutters, large pose variations and severe occlusions. To
improve its performance, a robust and discriminative feature extraction
methodology is particularly crucial. Recently, the feature alignment technique
driven by human pose estimation, that is, matching two person images with their
corresponding parts, increases the effectiveness of ReID to a certain extent.
However, we argue that there are still a few problems among these methods
such as imprecise handcrafted segmentation of body parts, and some improve-
ments can be further achieved. In this paper, we present a novel framework
called Mask-Guided Region Attention Network (MGRAN) for person ReID.
MGRAN consists of two major components: Mask-guided Region Attention
(MRA) and Multi-feature Alignment (MA). MRA aims to generate spatial
attention masks and meanwhile mask out the background clutters and occlu-
sions. Moreover,
the generated masks are utilized for region-level feature
alignment in the MA module. We then evaluate the proposed method on three
public datasets,
including Market-1501, DukeMTMC-reID and CUHK03.
Extensive experiments with ablation analysis show the effectiveness of this
method.

Keywords: Person re-identiﬁcation  Human pose estimation  Mask

1 Introduction

Person re-identiﬁcation (ReID) aims to identify the same individual across multiple
cameras. In general, it is considered as a sub-problem of image retrieval. Given a query
image containing a target pedestrian, ReID is to rank the gallery images and search for
the same pedestrian. It plays an important role in various surveillance applications,
such as intelligent security and pedestrian tracking.

In the past years, many methods [1–4] have been proposed to address the ReID
problem. However, it still remains as an incomplete task due to large pose variations,
complex background clutters, various camera views, severe occlusions and uncon-
trollable illumination conditions. Recently, with the improvement of human pose

© Springer Nature Switzerland AG 2020
H. W. Lauw et al. (Eds.): PAKDD 2020, LNAI 12085, pp. 286–298, 2020.
https://doi.org/10.1007/978-3-030-47436-2_22

Mask-Guided Region Attention Network for Person Re-Identiﬁcation

287

Patch

Rectangular RoI

Imprecise shapes of body parts set by handcraft, such as patches [1, 11] and rectangular

Fig. 1.
RoIs [9, 12], include extensive noise.

estimation [5–7], some researches [8–10] utilize the estimation results as spatial
attention maps to learn features from pedestrian body parts and then align them. These
methods achieve great success and prove that extracting features exactly from body
regions rather than background regions is helpful for ReID.

However, there are still notable problems in these methods concluded as follows. 1)
As shown in Fig. 1, these methods tend to extract features from imprecise part shapes
set by handcraft, such as patches [1, 11] and rectangular regions of interest (RoIs) [9,
12], which can introduce noise. 2) Part-level feature alignment which means matching
two pedestrians with their heads, arms, legs, and other body parts is improper for ReID.
3) Feature representation is not accurate and comprehensive enough.

In the ﬁrst problem, the main reason that the handcrafted shapes cannot precisely
describe the silhouettes of body parts is that the shapes of body parts are irregular.
Feature alignment based on these shapes can introduce noise from background clutters,
occlusions and even adjacent parts as in Fig. 1, leading to inaccurate matching. To deal
with this problem, we propose to use pedestrian masks as the spatial attention maps for
masking out clutters and meanwhile obtaining the ﬁner silhouettes of body parts both in
pixel-level, as shown in Fig. 2(a). These silhouettes obtained by pedestrian masks
should be more precise and closer to the reality of body shapes. For the second
problem, the works mentioned above generally align features based on part-level and
this is inappropriate for ReID. As walking is a dynamic process, and in this process, the
moving arms and legs have huge morphological changes and often cause heavy self-
occlusion, which implies that a body part will inevitably be occluded by other parts.
For example, left legs are often occluded by right legs. Due to self-occlusion, it is
difﬁcult to align features based on part-level. Furthermore, each pedestrian has his own
walking postures that are different from others’, which means his head, upper body and
lower body have their own morphological characters when walking. But the part-level
alignment may discard these characters, as shown in Fig. 2(b). Meanwhile, the head,
upper body and lower body are generally separate from each other in a walking
pedestrian, which indicates there is no self-occlusion among these three parts as
demonstrated in Fig. 2(b).

Based on the above analysis, it is concluded that region-level feature alignment
based on head, upper body and lower body is more reasonable for ReID. Furthermore,
apart
from self-occlusion, pedestrians may have some carry-on items, such as

288

C. Zhou and H. Yu

Keypoints
(Blue Dots)

Original Image     Pedestrian Mask   

Pedestrian Region   

Body Part

(a)

Original Image     

Pedestrian Mask     
(b)

Local Region

Fig. 2.
(a): Pedestrian masks can be used to mask out clutters and obtain the ﬁner silhouettes of
pedestrian body parts. (b): Pedestrians’ heads, upper bodies and lower bodies have their own
morphological characters which can not be presented by a single body part. For example, the
morphological characters of upper bodies are presented by arms and upper torsos, such as the
amplitude of arm swing (Yellow Arrow). (Color ﬁgure online)

backpacks, handbags and caps. These items are deﬁnitely helpful for ReID and we can
treat them as special parts of pedestrians, which should be included in the corre-
sponding local region like in Fig. 2(b). In the third problem, these methods like [1, 9,
12] only align the part features, considered as local features, and the global feature of
the whole pedestrian region is not considered. However, each pedestrian is intuitively
associated with a global feature including body shape, walking posture and so on,
which cannot be replaced by local features. Due to the neglect of global features, the
ﬁnal feature representation will not be comprehensive and robust enough. Meanwhile,
previous works [13, 14] extract the global feature from the entire pedestrian image
including background clutters and occlusions, which will introduce noise and lead to
the inaccuracy of feature representation. Here, we utilize pedestrian masks to redesign
the global features, removing clutters with masks ﬁrstly and then extracting the global
features of pedestrians. After these operations, multi-feature fusion can be used to align
features.

Based on above motivations, we propose a new Mask-Guided Region Attention
Network for person re-identiﬁcation. The contributions of our work can be summarized
as follows:

Mask-Guided Region Attention Network for Person Re-Identiﬁcation

289

(cid:129) To make the better use of feature alignment technique for person re-identiﬁcation, a
uniﬁed framework called Mask-Guided Region Attention Network (MGRAN) is
proposed.

(cid:129) To further reduce the noise from background clutters and occlusions, we explore to
utilize masks to separate pedestrians from them and obtain the ﬁner silhouettes of
pedestrian bodies.

(cid:129) Region-level feature alignment, based on head, upper body and lower body, is

introduced as a more appropriate method for ReID.

(cid:129) We redesign the global feature and utilize multi-feature fusion to improve the

accuracy and the completeness of feature representation.

2 Related Work

2.1 Person Re-Identiﬁcation

Recently, person re-identiﬁcation methods based on deep learning achieved great suc-
cess [13, 15, 16]. In general, these methods can be classiﬁed into two categories, namely
feature representation and distance metric learning. The ﬁrst category [1, 3, 17, 18] often
treats ReID as a classiﬁcation problem. These methods dedicate to design view-invariant
representations for pedestrians. The second category [19–21] mainly aims at measuring
the similarity between pedestrian images by learning a robust distance metric.

Among these methods, many of them [9, 12] achieved the success by feature
alignment. Numerous studies proved the importance of feature alignment for ReID. For
example, Su et al. [5] proposed a Pose-driven Deep Convolutional model (PDC) that
used Spatial Transformer Network (STN) to crop body regions based on pre-deﬁned
centers. Xu et al. [9] achieved the more precise feature alignment based on their
proposed network called Attention-Aware Compositional Network (AACN) and fur-
ther improved the performance of identiﬁcation. However, these methods align the part
features based on the body shapes set by handcraft, which is usually imprecise. In our
model, we utilize pedestrian masks in pixel-level to align features, intending to obtain
more precise information of body parts.

2.2

Instance Segmentation and Human Pose Estimation

With the rapid development of instance segmentation based on deep learning methods
such as Mask R-CNN [22] and the Fully Convolutional Networks (FCN) [23], now we
can easily obtain high-quality pedestrian masks which can be used in person re-
identiﬁcation. Furthermore, these instance segmentation methods can be naturally
extended to human pose estimation by modeling keypoint locations as one-hot masks.
We can further improve the performance of person re-identiﬁcation by integrating the
results of instance segmentation and human pose estimation.

290

C. Zhou and H. Yu

Mask-guided Region Attention

Multi-feature Alignment

Mask R-CNN

Keypoint Mask

Pedestrian Mask

ResNet-50

Feature Vector

Hadamard Product

Concatenation

Loss

Fig. 3. Mask-Guided Region Attention Network (MGRAN). Our proposed MGRAN consists of
two main components: Mask-guided Region Attention (MRA) and Multi-feature Alignment
(MA). MRA aims to generate two types of attention maps: pedestrian masks and human body
keypoint masks. MA utilizes the attention maps generated by MRA to obtain the pedestrian
region and the three associated local regions. Then the global feature and local features are
extracted and multi-feature fusion is used to align them.

2.3

Spatial Attention Mechanism

Spatial attention mechanism has achieved great success in understanding images and it
has been widely used in various tasks, such as semantic segmentation [24], object
detection [25] and person re-identiﬁcation [26]. For example, Chu et al. [6] proposed a
multi-context attention model for pose estimation. Inspired by these methods, we use
spatial attention maps to remove the undesirable clutters in pedestrian images. How-
ever, different from them, we use binary pedestrian masks as spatial attention maps to
obtain more precise information of pedestrian bodies.

3 Mask-Guided Region Attention Network

3.1 Overall Architecture

The overall framework of our Mask-Guided Region Attention Network (MGRAN) is
illustrated in Fig. 3. MGRAN consists of two main components: Mask-guided Region
Attention (MRA) and Multi-feature Alignment (MA).

Mask-Guided Region Attention Network for Person Re-Identiﬁcation

291

Head

Upper Body

Lower Body

Original Image   

Pedestrian Mask    

Keypoint Mask  

Local Region

Fig. 4. Two types of masks: pedestrian masks and keypoint masks. In this paper, we deﬁne four
keypoints (Blue Dots). By connecting two adjacent keypoints, we can divide the pedestrian
region into three local regions: the head, the upper body and the lower body. (Color ﬁgure online)

The MRA module aims to generate two kinds of attention maps: pedestrian masks
and human body keypoints. It is constructed by a two-branch neural network, which
predicts the attention maps of the pedestrians and their keypoints, respectively.

The MA module is constructed by a four-branch neural network. It utilizes the
estimated attention maps to extract global features and local features. A series of
extracted features are then fused for multi-feature alignment.

3.2 Mask-Guided Region Attention

Different from other works, we use binary masks as attention maps for highlighting
speciﬁc regions of human body in the image. With the rapid development of instance
segmentation, there are many alternative methods to generate pedestrian masks. In this
paper, we choose Mask R-CNN [22] to predict the masks due to its high accuracy and
ﬂexibility. As shown in Fig. 4, there are two types of masks: pedestrian masks and
keypoint masks. They are simultaneously learned in a uniﬁed form through our pro-
posed Mask-guided Region Attention module.
Pedestrian Masks P. A pedestrian mask P is the encoding of an input image’s spatial
layout. It is a binary encoding which means that the pixels of pedestrian region are
encoded as number 1 and the others are encoded as number 0. Following the original
article of Mask R-CNN, we set hyper-parameters as suggested by existing Faster R-
CNN work [27] and deﬁne the loss Lmask Pð Þ on each sampled RoI in Mask R-CNN as
the average binary cross-entropy loss,

Lmask Pð Þ ¼   1
N

XN
i¼1


P
i

 log r Pið

ð

Þ

 

Þ þ 1   P

i

  log 1   r Pið

ð

Þ

Þ;

ð1Þ

where N is the number of pixels in a predicted mask, r denotes the sigmoid function, Pi

is a single pixel in the mask, and P
is the corresponding ground truth pixel. Fur-
i
thermore, the classiﬁcation loss Lcls and the bounding-box loss Lbox of each sampled
RoI are set as indicated in [21].

Keypoint Masks K. Mask R-CNN can easily be extended to keypoints detection. We
model a keypoint’s location as a one-hot mask and use Mask R-CNN to predict four

292

C. Zhou and H. Yu

masks, one for each of the four keypoints as shown in Fig. 4. Following the original
article of Mask R-CNN, during training, we minimize the cross-entropy loss over an
m2-way softmax output for each visible ground-truth keypoint, which encourages a
single point to be detected.

3.3 Multi-feature Alignment

Based on the attention masks generated by Mask-guided Region Attention module, we
propose a Multi-feature Alignment (MA) module to align the global feature and local
features. MA consists of two main stages called Space Alignment (SA) and Multi-
feature Fusion (MF). The complete structure of MA is shown in Fig. 3.

Space Alignment (SA). Space Alignment aims to obtain the pedestrian region and the
three local regions. Based on the attention masks generated by MRA module, we
propose a simple and effective approach to obtain them. Speciﬁcally, we ﬁrstly apply
Hadamard Product between the original image M and the corresponding pedestrian
mask P to obtain the pedestrian region, as follows:
 ¼ M  P;

ð2Þ
where,  denotes the Hadamard Product operator which performs element-wise product
on two matrices or tensors and M
denotes the pedestrian region. It is worth noting that
we use Hadamard Product on the original image to guarantee the accuracy of features.
Some works [9, 12] use spatial attention maps on processed data such as data processed
by convolution, which will introduce noise into the attention region from other regions
in the image. Secondly, based on the obtained pedestrian body region, we utilize the
four keypoint masks to obtain the three local regions by connecting two adjacent
keypoints and segmenting the pedestrian region, as shown in Fig. 4.

M



Multi-feature Fusion (MF). In this module, we use four ResNet-50 networks [28] to
extract the features of the four regions generated by SA module, respectively. Then
feature fusion is used to align features, as follows:

 



	


;

F ¼ Concat

ð3Þ
where Concat ð Þ denotes the concatenation operation on feature vectors, f g represents
the global feature of the whole pedestrian body region, f 1
l denote the features
of the three local regions respectively, and F is the ﬁnal feature vector for the input
pedestrian image.

l and f 3

f g f 1

l f 2

l f 3
l

l , f 2

Overall, our framework integrated the MRA and MA to extract features for input

pedestrian images.

3.4

Implementation Details

We construct the Mask R-CNN model with a ResNet-50-FPN backbone and use the
annotated person images in the COCO dataset [29] to train it. Furthermore, the ﬂoating-
number mask output is binarized at a threshold of 0.5. In MF, the four ResNet-50

Mask-Guided Region Attention Network for Person Re-Identiﬁcation

293

Table 1. The details of three public datasets used in experiments.

# IDs # cameras # resolution
Datasets
64  128
Market-1501 [31]
1501 6
Vary
DukeMTMC-reID [32] 1812 8
Vary
1467 2
CUHK03 [1]

networks share the same parameters and we use the Margin Sample Mining Loss
(MSML) [30] to conduct distance metric learning based on the four features extracted
by ResNet-50. We scale the all images input into Mask R-CNN and ResNet-50 with a
factor of 1/256. Finally, MRA and MA are trained independently.

4 Experiments

In this section, the performance of Mask-Guided Region Attention Network (MGRAN)
is compared with several state-of-the-art methods on three public datasets. Further-
more, detailed ablation analysis is conducted to validate the effectiveness of MGRAN
components.

4.1 Datasets and Protocols

We evaluate our method on three large-scale public person ReID datasets, including
Market-1501 [31], DukeMTMC-reID [32] and CUHK03 [1], details of them are shown
in Table 1. For fair comparison, we follow the ofﬁcial evaluation protocols of each
dataset. For Market-1501 and DukeMTMC-reID, rank-1 identiﬁcation rate (%) and
mean Average Precision (mAP) (%) are used. For CUHK03, Cumulated Matching
Characteristics (CMC) at rank-1 (%) and rank-5 (%) are adopted.

4.2 Comparison with the State-of-the-Art Methods

We choose 13 methods in total with state-of-the-art performance for comparisons with
our proposed framework MGRAN. These methods can be categorized into two classes
according to whether human pose information is used. The Spindle-Net (Spindle) [12],
Deeply-Learned Part-Aligned Representations (DLPAR) [10], MSCAN [33], and the
Attention-Aware Compositional Network (AACN) [9] are pose-relevant. The Online
Instance Matching (OIM) [14], Re-ranking [34], the deep transfer learning method
(Transfer) [35], the SVDNet [15], the pedestrian alignment network (PAN) [36], the
Part-Aligned Representation (PAR) [10], the Deep Pyramid Feature Learning (DPFL)
[13], DaF [37] and the null space semi-supervised learning method (NFST) [38] are
pose-irrelevant. The experimental results are presented in Table 2, 3 and 4.

Based on the experimental results, it is obvious that our MGRAN framework
outperforms the compared methods, showing the advantages of our approach. To be
speciﬁc, compared with the second best method on each dataset, our framework
achieves 6.10%, 1.89%, 1.28%, 7.62% and 6.57% rank-1 accuracy improvement on

294

C. Zhou and H. Yu

Table 2. Comparison results on Market-1501 dataset.

Market-1501

Spindle [12]
DLPAR [10]
MSCAN [33]
SVDNet [15]
PAN [36]
Re-ranking [34]
NFST [38]
MGRAN (Ours)

Single query
Rank-1
76.90
81.00
80.31
82.30
82.81
77.11
61.02
88.91

mAP
–
63.40
57.53
62.10
63.35
63.63
35.68
78.03

Multiplequery
Rank-1
–

mAP
–

–

–

–
88.18
–
71.56
90.07

–

–

–
71.72
–
46.03
81.30

Table 3. Comparison results on DukeMTMC-reID dataset.

DukeMTMC-reID Rank-1 mAP
56.80
SVDNet [15]
OIM [14]
–
51.51
PAN [36]
AACN [9]
59.25
63.57
MGRAN (Ours)

76.70
68.10
71.59
76.84
78.12

Table 4. Comparison results on CUHK03 dataset.

CUHK03

Detected

Labeled
Rank-1 Rank-5 Rank-1 Rank-5
85.40
PAR [10]
62.55
NFST [38]
81.80
SVDNet [15]
43.00
DPFL [13]
27.50
DaF [37]
Transfer [35]
85.40
MGRAN (Ours) 93.02

81.60
54.70
–
40.70
26.40
84.10
90.67

97.30
84.75
–

97.60
90.05
–

–
98.94

–

–

–
98.21

–

–

Market-1501 (Single Query), Market-1501 (Multiple Query), DukeMTMC-reID,
CUHK03 (Labeled) and CUHK03 (Detected), respectively. Furthermore, compared
with the second best method on Market-1501 and DukeMTMC-reID, 14.40%, 9.58%
and 4.32% mAP improvement on Market-1501 (Single Query), Market-1501 (Multiple
Query) and DukeMTMC-reID are achieved, respectively.

Mask-Guided Region Attention Network for Person Re-Identiﬁcation

295

Table 5. Effectiveness of MF. MGRAN   GF means removing global features in ﬁnal feature
vectors.

Ablation Analysis

MGRAN   GF
MGRAN

Market-1501
Single Query
Rank-1
86.30
88.91

mAP
74.26
78.03

Multiple Query
Rank-1
87.82
90.07

mAP
80.53
81.30

DukeMTMC-reID
mAP
Rank-1

77.31
78.12

60.10
63.57

Table 6. Effectiveness of RFA. MGRAN-PL means aligning features based on part-level.
MGRAN-RL means aligning features based on region-level.

Ablation Analysis CUHK03

Detected

Labeled
Rank-1 Rank-5 Rank-1 Rank-5
91.83
93.02

89.35
90.67

97.41
98.94

96.75
98.21

MGRAN-PL
MGRAN-RL

4.3 Ablation Analysis

In this section, we evaluate the effect of our proposed multi-feature fusion and region-
level feature alignment by ablation analysis.

Multi-feature Fusion (MF). We verify the effectiveness of MF on Market-1501 and
DukeMTMC-reID dataset by removing global features in ﬁnal feature vectors. As shown
in Table 5, MF increases the rank-1 accuracy by 2.61%, 2.25% and 0.81% on Market-
1501 (Single Query), Market-1501 (Multiple Query) and DukeMTMC-reID. Further-
more, 3.77%, 0.77% and 3.47% mAP improvement on Market-1501 (Single Query),
Market-1501 (Multiple Query) and DukeMTMC-reID are achieved based on MF.

Region-Level Feature Alignment (RFA). We align features based on part-level and
region-level respectively to verify the effectiveness of our proposed region-level feature
alignment. Speciﬁcally, we replace region-level feature alignment in MGRAN with
part-level feature alignment and keep the other parts unchanged. As shown in Table 6,
RFA increases the rank-1 accuracy by 1.19% and 1.32% on CUHK03 (Labeled) and
CUHK03 (Detected). Meanwhile, RFA increases the rank-5 accuracy by 1.53% and
1.46% on CUHK03 (Labeled) and CUHK03 (Detected). The experimental results show
the usefulness of our proposed RFA.

296

C. Zhou and H. Yu

5 Conclusion

In this paper, we propose a novel Mask-Guided Region Attention Network (MGRAN)
for person re-identiﬁcation to deal with the clutter and misalignment problem. MGRAN
consists of two main components: Mask-guided Region Attention (MRA) and Multi-
feature Alignment (MA). MRA generates spatial attention maps to mask out undesir-
able clutters and obtain ﬁner silhouettes of pedestrian bodies. MA aims to align features
based on region-level which is more appropriate for ReID. Our method has achieved
some success, but with the rapid development of science, a great number of excellent
technologies have been created, such as GAN, and in the future work, we propose to
use these technologies to further improve the performance of ReID.

Acknowledgements. We are grateful for the ﬁnancial support of the China Postdoctoral Science
Foundation (grant no. 2018T110531), the National Natural Science Foundation of China (grant
no. 11501302), and the Natural Science Foundation of Nanjing University of Posts and
Telecommunications NUPTSF (grant no. NY219080).


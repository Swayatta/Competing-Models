1  Introduction  Chinese text error correction plays an important role in many NLP related scenarios (Martins and Silva, 2004; Aﬂi et al., 2016; Wang et al., 2018; Burstein and Chodorow, 1999).
For text-aligned situation, many approaches apply the detect-correct framework, which is to detect the positions of wrong characters ﬁrst and then correct them (Hong et al., 2019; Zhang et al., 2020; Cheng et al., 2020).
For text non-aligned situations, the reversed order error or complex structural change with multiple errors are not in our scope, ﬁrst because we target to cover common mistakes made by Chinese native speakers, which are different from foreign Chinese learners in Chinese error correction(GEC) (Wang et al., 2020; Qiu and Qu, 2019) task, second because the mentioned complex errors are beyond our model settings.
The former is inspired by machine translation, which sets wrong sentences as input and correct sentences as output (Zhao et al., 2019; Kaneko et al., 2020; Chollampatt et al., 2019; Zhao and Wang, 2020; Lichtarge et al., 2019; Ge et al., 2018; Junczys-Dowmunt et al., 2018).
Such approaches require a large number of training data and may generate uncontrollable results (Kiyono et al., 2019; Koehn and Knowles, 2017).
The latter takes wrong sentences as input and modiﬁcation operations of each token as output (Awasthi et al., 2019; Malmi et al., 2019; Omelianchuk et al., 2020).
The task can be viewed as a sequence transformation problem with a mapping function f : X → Y  Figure 1: Architecture of the alignment-agnostic model  2.2 Model As illustrated in Figure 1, the basic structure of our model includes a detection network evolved from ELECTRA discriminator (Clark et al., 2020) and a correction network based on BERT MLM (Devlin et al., 2019).
The architecture of ELECTRA discriminator has been described in Clark et al. (2020).
3 Experiments  3.1 Datasets and Metrics  Chinese text error correction tasks mainly have two public datasets: the benchmark of SIGHAN 2015 (Tseng et al., 2015) which only contains text-aligned data and the competition of CGED 2020 (Rao et al., 2020) which contains text nonaligned data.
To ensure comparability, we also trained another model on a considerably larger train set to be consistent with SpellGCN’ (Cheng et al., 2020), which has 281379 passages in train set.
For CGED 2020 dataset and SIGHANsynthesized dataset, we adopted the M 2 score (Dahlmeier and Ng, 2012) and ERRANT (Bryant et al., 2017) to evaluate models’ performance, which are two commonly used evaluation tools for text non-aligned situations.
The other is a supervised method by masking mistaken characters  Test Set  Method  CGED 2020  SIGHAN-synthesized  Copy-augmented(2019)  Lasertagger(2019)  PIE(2019) our model  Copy-augmented(2019)  Lasertagger(2019)  PIE(2019) our model  Prec.
The ﬁrst 5 lines implies that our method outperforms the method Soft-Masked BERT (Zhang et al., 2020) by 1.8% on F1 score in correction phrase.
Compared with the previous SOTA method SpellGCN (Cheng et al., 2020), our model showed higher precision and comparable F1 score.
Since Copy-augmented (Zhao et al., 2019), as a Seq2Seq model, requires a large size of training data to get an acceptable result, it underperforms Lasertagger (Malmi et al., 2019) and PIE (Awasthi et al., 2019) models on both two datasets with a small training sample size.

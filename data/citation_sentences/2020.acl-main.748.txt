1  Introduction  Mining and analyzing the constantly-growing unstructured text in the bio-medical domain offers great opportunities to advance scientiﬁc discovery (Gonzalez et al., 2015; Fleuren and Alkema, 2015) and improve the clinical care (Rumshisky et al., 2016; Liu et al., 2019).
Techniques for concept normalization have been advancing, thanks in part to recent shared tasks including clinical disorder normalization in 2013 ShARe/CLEF (Suominen et al., 2013) and 2014 SemEval Task 7 Analysis of Clinical Text (Pradhan et al., 2014), and adverse drug event normalization in Social Media Mining for Health (SMM4H) (Sarker et al., 2018; Weissenbacher et al., 2019).
Most existing systems use a string-matching or dictionary look-up approach (Leal et al., 2015; D’Souza and Ng, 2015; Lee et al., 2016), which are limited to matching morphologically similar terms, or supervised multi-class classiﬁers (Belousov et al., 2017; Tutubalina et al., 2018; Niu et al., 2019; Luo et al., 2019a), which may not generalize well when there are many concepts in the ontology and the concept types that must be predicted do not all appear in the training data.
In contrast to previous list-wise classiﬁers (Murty et al., 2018) which only take the concept mention as input, our BERT-based list-wise classiﬁer takes both the concept mention and the candidate concept name as input, and is thus able to handle concepts that never appear in the training data.
These approaches differ in how they construct dictionaries, such as collecting concept mentions from the labeled data as extra synonyms (Leal et al., 2015; Lee et al., 2016), and in different string matching techniques, such as string overlap and edit distance (Kate, 2016).
Two of the most commonly used knowledge-intensive concept normalization tools, MetaMap (Aronson, 2001) and cTAKES (Savova et al., 2010) both employ rules to ﬁrst generate lexical variants for each noun phrase and then conduct dictionary look-up for each variant.
Several systems (D’Souza and Ng, 2015; Jonnagaddala et al., 2016) have demonstrated that rule-based concept normalization systems achieve performance competitive with other approaches in a sieve-based approach that carefully selects combinations and orders of dictionaries, exact and partial matching,  and heuristic rules.
We divide the machine learning approaches into two categories, classiﬁcation (Savova et al., 2008; Stevenson et al., 2009; Limsopatham and Collier, 2016; Yepes, 2017; Festag and Spreckelsen, 2017; Lee et al., 2017; Tutubalina et al., 2018; Niu et al., 2019) and learning to rank (Leaman et al., 2013; Liu and Xu, 2017; Li et al., 2017; Nguyen et al., 2018; Murty et al., 2018).
They differ in using different architectures, such as Gated Recurrent Units (GRU) with attention mechanisms (Tutubalina et al., 2018), multi-task learning with auxiliary tasks to generate attention weights (Niu et al., 2019), or pre-trained transformer networks (Li et al., 2019; Miftahutdinov and Tutubalina, 2019); different sources for training word embeddings, such as Google News (Limsopatham and Collier, 2016) or concept deﬁnitions from the Uniﬁed Medical Language System (UMLS) Metathesaurus (Festag and Spreckelsen, 2017); and different input representations, such as using character embeddings (Niu et al., 2019).
All classiﬁcation approaches share the disadvantage that the output space must be the same size as the number of concepts to be predicted, and thus the output space tends to be small such as 2,200 concepts in (Limsopatham and Collier, 2016) and around 22,500 concepts in (Weissenbacher et al., 2019).
Researchers have applied point-wise learning to rank (Liu and Xu, 2017; Li et al., 2017), pairwise learning to rank (Leaman et al., 2013; Nguyen  8453et al., 2018), and list-wise learning to rank (Murty et al., 2018; Ji et al., 2019) on concept normalization.
DNorm (Leaman et al., 2013), based on a pair-wise learning-to-rank model where both mentions and concept names were represented as TFIDF vectors, was the ﬁrst to use learning-to-rank for concept normalization and achieved the best performance in the ShARe/CLEF eHealth 2013 shared task.
List-wise learning-to-rank approaches are both computationally more efﬁcient than pairwise learning-to-rank (Cao et al., 2007) and empirically outperform both point-wise and pair-wise approaches (Xia et al., 2008).
There are two implementations of list-wise classiﬁers using neural networks for concept normalization: Murty et al. (2018) treat the selection of the best candidate concept as a ﬂat classiﬁcation problem, losing the ability to handle concepts not seen during training; Ji et al.
3.2.1 BERT-based multi-class classiﬁer BERT (Devlin et al., 2019) is a contextualized word representation model that has shown great performance in many NLP tasks.
3.2.2 Lucene-based dictionary look-up  system  Multi-pass sieve rule based systems (D’Souza and Ng, 2015; Jonnagaddala et al., 2016; Luo et al., 2019b) achieve competitive performance when used with the right combinations and orders of different dictionaries, exact and partial matching, and heuristic rules.
4 Experiments 4.1 Datasets Our experiments are conducted on three social media datasets, AskAPatient (Limsopatham and Collier, 2016), TwADR-L (Limsopatham and Collier, 2016), and SMM4H-17 (Sarker et al., 2018), and one clinical notes dataset, MCN (Luo et al., 2019b).
We follow the 10-fold cross validation (CV) conﬁguration in Limsopatham and Collier (2016) which provides 10 sets of train/dev/test splits.
We again follow the 10-fold cross validation conﬁguration deﬁned by Limsopatham and Collier (2016).
MCN The MCN dataset consists of 13,609 concept mentions drawn from 100 discharge summaries from the fourth i2b2/VA shared task (Uzuner et al., 2011).
4.2 Uniﬁed Medical Language System The UMLS Metathesaurus (Bodenreider, 2004) links the same concept  similar names  for  8456from nearly 200 different vocabularies such as SNOMED-CT, MedDRA, RxNorm, etc.
For all experiments, we use BioBERT-base (Lee et al., 2019), which further pre-trains BERT on PubMed abstracts (PubMed) and PubMed Central full-text articles (PMC).
5https://github.com/huggingface/  transformers  WordCNN Limsopatham and Collier (2016) use convolutional neural networks over pre-trained word embeddings to generate a vector representation for each mention, and then feed these into a softmax layer for multi-class classiﬁcation.
WordGRU+Attend+TF-IDF Tutubalina et al. (2018) use a bidirectional GRU with attention over pre-trained word embeddings to generate a vector representation for each mention, concatenate such vector representations with the cosine similarities of the TF-IDF vectors between the mention and all other concept names, and then feed the concatenated vector to a softmax layer for multi-class classiﬁcation.
BERT+TF-IDF Miftahutdinov and Tutubalina (2019) take similar approach as Tutubalina et al. (2018), but use BERT to generate a vector representation for each mention.
CharCNN+Attend+MT Niu et al. (2019) use a multi-task attentional character-level convolution neural network.
CharLSTM+WordLSTM Han et al. (2017) ﬁrst use a forward LSTM over each character of the mention and its corresponding character class such as lowercase or uppercase to generate a character-level vector representation, then use another bi-directional LSTM over each word of the mention to generate a word-level representation.
LR+MeanEmbedding Belousov et al. (2017) calculate the mean of three different weighted word embeddings pre-trained on GoogleNews, Twitter and DrugTwitter as vector representations for  8457Approach WordCNN (Limsopatham and Collier, 2016) WordGRU+Attend+TF-IDF (Tutubalina et al., 2018) BERT+TF-IDF (Miftahutdinov and Tutubalina, 2019) CharCNN+Attend+MT (Niu et al., 2019) CharLSTM+WordLSTM (Han et al., 2017) LR+MeanEmbedding (Belousov et al., 2017) BERT BERT + BERT-rank BERT + BERT-rank + ST-reg BERT + gold + BERT-rank BERT + gold + BERT-rank + ST-reg  TwADR-L Dev 47.08 48.07 47.98 52.70 52.84  Test 44.78 46.46 44.05 46.32 47.02 49.69 50.81  AskAPatient Dev Test 81.41 85.71 84.65 87.52 88.63 87.10 88.14 88.26 87.46 87.92 89.06 89.68 88.51  SMM4H-17 Dev Test 89.64 87.20 87.70 87.36 84.74 87.66 84.44 84.66 88.24 90.16 88.57 88.87 91.08  Table 2: Comparisons of our proposed concept normalization architecture against the current state-of-the-art performances on TwADR-L, AskAPatient, and SMM4H-17 datasets.
Sieve-based Luo et al. (2019b) build a sievebased normalization model which contains exactmatch and MetaMap (Aronson, 2001) modules.
6An ensemble of  three systems (including CharLSTM+WordLSTM and LR+MeanEmbedding) achieved 88.7% accuracy on the SMM4H-17 dataset (Sarker et al., 2018).
Approach Sieve-based (Luo et al., 2019b) Lucene Lucene+BERT-rank Lucene+BERT-rank+ST-reg Lucene+gold+BERT-rank Lucene+gold+BERT-rank+ST-reg  MCN  Dev  83.56 84.44 86.89 88.59  Test 76.35 79.25 82.75 83.56 84.77 86.56  Table 3: Accuracy of our proposed concept normalization architecture on MCN dataset.
The Lucene-based candidate generator ﬁnds this concept, but only  7Miftahutdinov and Tutubalina (2019) use the same architecture as our BERT-based multi-class classiﬁer (row 7), but they achieve 89.28% of accuracy on SMM4H-17.
Lee et al. (2017) notes that AskAPatient and TwADR-L have issues including  8459duplicate instances, which can lead to bias in the system; many phrases have multiple valid mappings to concepts but the context necessary to disambiguate is not part of the dataset; and the 10-fold cross-validation makes training complex models unnecessarily expensive.

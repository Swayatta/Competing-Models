In particular, sequence-to-sequence models have found adoption in neural machine translation (NMT (Bahdanau et al., 2014; Luong et al., 2015)), neural semantic parsing (NSP (Dong and Lapata, 2016)), and beyond.
While basic sequence-to-sequence models have shown impressive results on these tasks, recent work (Lake and Baroni, 2018; Keysers et al., 2019; Kim and Linzen, 2020) have presented the disconcerting ﬁnding that these models fail to generalize to novel combinations of elements observed in the training set (see Section 2).
Therefore, several models and methods with improved compositional generalization have recently been proposed (Liu et al., 2020; Li et al., 2019; Russin et al., 2020; Guo et al., 2020a; Gordon et al., 2019; Herzig and Berant, 2020; Furrer et al., 2020; Andreas, 2020; Guo et al., 2020b; Herzig et al., 2021) In this work, we consider the task of detecting compositionally out-of-distribution (OOD) exam ples, which, to the best of our knowledge has not been investigated before.
2 Background  Several recent works have investigated the generalization properties of commonly used sequence-tosequence models, in particular their ability to learn to process and produce novel combinations of elements observed during training (Lake and Baroni, 2018; Keysers et al., 2019; Kim and Linzen, 2020).
Lake and Baroni (2018) propose the SCAN dataset, which consists of natural language utterances (input) and action sequences (output), and perform an analysis of the generalization performance of sequence-to-sequence models on different splits of the dataset.
Keysers et al. (2019) performed their analysis on the CFQ dataset that provides tens of thousands of automatically generated question/SPARQL-query pairs and provides maximum compound divergence (MCD) splits.
Keysers et al. (2019) also provide MCD splits for the SCAN dataset.
3 Detecting OOD examples  In this work, we focus on OOD detection methods that build on the predictive distributions of discriminative task-speciﬁc models (extending the work of Hendrycks and Gimpel (2017)).
These methods have the advantage that they are easy to use in existing models and do not require additional models or additional training (unlike for example generative modeling (Nalisnick et al., 2018; Ren et al., 2019)).
Previous work has shown that neural network models can produce incorrect predictions with high conﬁdence on OOD inputs (Nguyen et al., 2015), which can be detrimental for detecting such inputs.
3.1 MC Dropout To take model uncertainty into account, Bayesian approaches can be used (Louizos and Welling, 2017; Maddox et al., 2019; Malinin and Gales, 2018).
A simple method for approximating the predictive uncertainty under a Bayesian posterior distribution over model parameters, is MC Dropout (Gal and Ghahramani, 2016).
3.2 Homogeneous ensemble Another method often used for uncertainty quantiﬁcation are deep ensembles (Lakshminarayanan et al., 2017), where K models with the same architecture and hyperparameters are trained in parallel starting with different initalizations.
We also combine heterogeneous ensembles and MC dropout, the approach for which is described in Appendix C. 4 Experiments1 Datasets: We experiment with the SCAN (Lake and Baroni, 2018) and CFQ (Keysers et al., 2019) datasets mentioned in Section 2.
Models: transformer based (Vaswani et al., 2017) and a GRU+attention (Cho et al., 2014) based sequenceto-sequence model in our experiments.
The models are trained using Adam (Kingma and Ba, 2015), with an initial learning rate of 5 ∗ 10−4.
The effect of homogeneous ensemble: The regular (homogeneous) deep ensemble (Lakshminarayanan et al., 2017) leads to signiﬁcant improvements of the OOD detection ability across all tested architectures and datasets.
While some recent works (Fomicheva et al., 2020; Malinin and Gales, 2021) investigate similar methods for structured prediction (for NMT and automated speech recognition), to the best of our knowledge, our work is the ﬁrst to investigate compositional OOD detection for NSP.

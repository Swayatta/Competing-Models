Introduction  1 Euphemisms—ordinary-sounding and innocentlooking words—have long been used in human communication as an instrument to conceal secret information (Bellman, 1981).
A primary motive of their use on social media is to evade automatic content moderation efforts enforced by such platforms (Cambridge Consultants, 2019; Yuan et al., 2018).
Research on automatic euphemism detection has recently received increased attention in the  natural language processing communities (Durrett et al., 2017; Magu and Luo, 2018; Pei et al., 2019; Felt and Riloff, 2020), and the security and privacy communities (Zhao et al., 2016; Yang et al., 2017; Yuan et al., 2018; Hada et al., 2020; Zhu et al., 2021).
Our paper focuses on the task of euphemistic phrase detection—detecting phrases that are used as euphemisms for a list of target keywords—by extending the state-of-the-art single-word euphemism detection algorithm proposed by Zhu et al. (2021).
Our proposed approach ﬁrst mines quality phrases from the text corpus using AutoPhrase (Shang et al., 2018; Liu et al., 2015), a data-driven phrase mining tool.
Finally, we rank the pre-selected candidates using SpanBERT (Joshi et al., 2020), a pre-training Masked Language Model (MLM) that is designed to better predict the span of tokens (i.e., phrases) in text.
Evaluating on the benchmark drug dataset in Zhu et al. (2021), we ﬁnd that our proposed approach yields euphemistic phrase detection results that are 20-50% higher than a set of strong baseline methods.
Speciﬁcally, we use the word2vec algorithm (Mikolov et al., 2013a,b) to learn the embeddings for all the words and phrases.2 Relying on the distributional hypothesis that semantically similar words occur in linguistically similar contexts, we assume that the euphemistic phrases should not be too far from the target keywords on the embedding space.
2.3 Euphemistic Phrase Ranking We extract contextual information of the target keywords and ﬁlter out uninformative contexts, following Zhu et al. (2021).
Toward ranking the candidates for ﬁlling in the mask, a common approach is to use BERT (Devlin et al., 2019), but BERT can be used to only rank single words.
Therefore, we select SpanBERT (Joshi et al., 2020) to rank the candidates, because it is designed to better represent and predict contiguous spans of text and it enables the likelihood calculation of multi-word candidates in a given context.
Our proposed approach for euphemistic phrase detection has three stages (shown in Figure 1): 1) Mining quality phrases, 2) Pre-selecting euphemistic phrase candidates using cosine similarities of word2vec embeddings (Mikolov et al., 2013a,b), and 3) Ranking euphemistic phrases with a masked language model.
We select AutoPhrase (Shang et al., 2018; Liu et al., 2015), which has demonstrated superior phrase mining performance in a wide range of settings, to mine quality phrases.
By incorporating distant supervision (i.e., Wikipedia) and part-of-speech tags as Shang et al. (2018), we empirically ﬁnd that AutoPhrase can extract meaningful phrases successfully.
SentEuph Word2vec EigenEuph EPD-rank-all  EPD-ILM  EPD  P @10 0.00 0.10 0.10 0.20 0.00 0.30  P @20 0.00 0.10 0.15 0.25 0.10 0.30  P @30 0.03 0.07 0.13 0.20 0.10 0.27  P @50 0.02 0.06 0.10 0.16 0.12 0.22  3 Empirical Evaluation  We evaluate our proposed model (denoted as “EPD”) and the following baselines on the benchmark drug dataset in Zhu et al. (2021), and compare it with the following baseline models:  • SentEuph (Felt and Riloff, 2020) recognizes euphemisms by sentiment analysis and a bootstrapping algorithm for semantic lexicon induction.
• EigenEuph (Magu and Luo, 2018) leverages word and phrase embeddings (following Section 2.1 and 2.2) and a community detection algorithm, to generate a cluster of euphemisms by the ranking metric of eigenvector centralities.
• EPD-ILM ranks the pre-selected phrase candidates by Inﬁlling by Language Modeling (ILM)5 (Donahue et al., 2020) instead of SpanBERT.
Following Zhu et al. (2021), we use the evaluation metric precision at k (P @k) to compare the generated candidates of each method with the ground  5https://github.com/chrisdonahue/ilm  Table 1: Results on euphemistic phrase detection.
We did not perform experiments on the weapon and the sexuality datasets used in Zhu et al. (2021), because most euphemisms used are single words rather than multi-word phrases.
Neither did we perform experiments on the hate speech dataset collected by Magu and Luo (2018) since the dataset was not publicly available.
Besides, EPD shares a similar model architecture with the algorithm proposed by Zhu et al. (2021), shown to be robust across various datasets.
Existing euphemism detection work have established a number of models by supervised (Pei et al., 2019), semi-supervised (Durrett et al., 2017) and unsupervised learning schemes (Zhao et al., 2016; Magu and Luo, 2018), on diverse categories and platforms (Yang et al., 2017; Hada et al., 2020), with and without distantsupervision (Portnoff et al., 2017; Felt and Riloff, 2020).
Without requiring any online search services, one major line of existing work have relied on static word embeddings (e.g., word2vec) in combination with network analysis (Taylor et al., 2017; Magu and Luo, 2018), sentiment analysis (Felt and Riloff, 2020), and semantic comparison across corpora (Yuan et al., 2018).
Therefore, Zhu et al. (2021) propose to explicitly harness the contextual information, formulate the problem as an unsupervised ﬁll-in-the-mask problem (Devlin et al., 2019; Donahue et al., 2020), and solve it by a masked language model with state-of-the-art results.
Our work bridges this gap by extending the state-of-the-art euphemism detection approach proposed by Zhu et al. (2021) and achieves holistic euphemism detection by enabling the detection of euphemistic phrases.
By mining quality phrases from the text corpus, pre-selecting euphemistic phrase candidates, and ranking phrases by a masked language model, we, for the ﬁrst time, achieve euphemistic phrase detection automatically.8 Moreover, we discover new euphemisms that are not even on the ground truth list, which is  7Felt and Riloff (2020) achieves euphemistic phrases de tection, with additional manual ﬁltering process.
Just like Zhu et al. (2021), our analyses relying on user-generated content do not constitute human subjects research, and are thus not within the purview of the IRB.9
